{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6yoVGzf4qOM",
        "outputId": "69593e8f-7271-47a0-9d23-fe18da234f1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWYxOH1U49Lo",
        "outputId": "26d3999c-60c2-48fb-daeb-08a1d921e050"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/HW5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/HW5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izdqvgwbivBC",
        "outputId": "efd50b3b-49b4-4d31-bdfc-0ae97ec3601b"
      },
      "source": [
        "# !pip install numpy==1.16.2\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "# !pip install torch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchsummary \n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "!pip install pytorch_ssim\n",
        "import pytorch_ssim\n",
        "\n",
        "import math\n",
        "from math import exp\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "from os import path\n",
        "import gc\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.5\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting pytorch_ssim\n",
            "  Downloading pytorch_ssim-0.1.tar.gz (1.4 kB)\n",
            "Building wheels for collected packages: pytorch-ssim\n",
            "  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-py3-none-any.whl size=2026 sha256=7357c78b57e7a684402df4262c64dbed452df2446773f11037b461e220dc70ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/20/09/ebf5e58bdf2560c760074cd140b7f7b0c882e216feabf1ae30\n",
            "Successfully built pytorch-ssim\n",
            "Installing collected packages: pytorch-ssim\n",
            "Successfully installed pytorch-ssim-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-CJn2R5jDtJ",
        "outputId": "d6745d72-bc21-4d89-c7fa-4e472767bf7d"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 18370058781790648910, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14512029696\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 13301782278046349956\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WCH1DEIn-Yn",
        "outputId": "e873d878-17c5-46f6-8abf-5478144b6584"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "num_workers = 2 if cuda else 0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTrS9IUHjkA8"
      },
      "source": [
        "transform = transforms.Compose([          \n",
        "            transforms.ToTensor(),\n",
        "            ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ65uXCfjqxj"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_in_folder, image_out_folder=None, transform=None):\n",
        "    self.image_in_folder = image_in_folder\n",
        "    self.image_in_paths = sorted(os.listdir(image_in_folder))\n",
        "    if image_out_folder is not None:\n",
        "      self.image_out_folder = image_out_folder\n",
        "      self.image_out_paths = sorted(os.listdir(image_out_folder))\n",
        "    else:\n",
        "      self.image_out_folder = None  \n",
        "    self.transform = transform\n",
        "            \n",
        "  def __getitem__(self, index):\n",
        "    x = Image.open(self.image_in_folder + self.image_in_paths[index])\n",
        "    x = x.convert('RGB')\n",
        "    if self.image_out_folder is not None:\n",
        "      y = Image.open(self.image_out_folder + self.image_out_paths[index])\n",
        "      y = y.convert('RGB')\n",
        "    else:\n",
        "      y = self.image_in_paths[index]\n",
        "    if self.transform is not None:\n",
        "        x = self.transform(x)\n",
        "        p = transforms.Compose([transforms.Resize((x.size()[-2]*4, x.size()[-1]*4))])\n",
        "        x = p(x)\n",
        "        if self.image_out_folder is not None:\n",
        "          y = self.transform(y)\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_in_paths)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP5IK5SDkjwh"
      },
      "source": [
        "train_x = 'HW5_IDLS21/HW5_train_val/DIV2K_train_LR_bicubic/X4/'\n",
        "train_y = 'HW5_IDLS21/HW5_train_val/DIV2K_train_HR/'\n",
        "train_dataset = MyDataset(train_x, train_y, transform)\n",
        "train_loader_args = dict(shuffle=True, batch_size=1, num_workers=num_workers, pin_memory=True, drop_last=True) \\\n",
        "                    if cuda else dict(shuffle=True, batch_size=1)\n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
        "del train_x, train_y\n",
        "\n",
        "val_x = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_LR_bicubic/X4/'\n",
        "val_y = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_HR/'\n",
        "val_dataset = MyDataset(val_x, val_y, transform)\n",
        "val_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "val_loader = DataLoader(val_dataset, **val_loader_args)\n",
        "del val_x, val_y\n",
        "\n",
        "# test_x_large = 'HW5_IDLS21/HW5_test/large_test/'\n",
        "test_x_large = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_LR_bicubic/X4/'\n",
        "test_dataset = MyDataset(test_x_large, None, transform)\n",
        "test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)\n",
        "del test_x_large"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7tvTF1soPKD",
        "outputId": "934a0b81-ed08-4504-b488-4649f5401376"
      },
      "source": [
        "print(test_dataset.__getitem__(1)[0].size(), test_dataset.__getitem__(1)[1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1356, 2040]) 0802x4.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd6JJo2NodQ2"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.l1 = nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.l2 = nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.l3 = nn.MaxPool2d(2, return_indices=True)\n",
        "    self.d = nn.Dropout(0.1)\n",
        "    self.l4 = nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=False)\n",
        "    self.l5 = nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False)\n",
        "    self.l6 = nn.MaxPool2d(2, return_indices=True)\n",
        "    self.l7 = nn.Conv2d(128, 256, 3, stride=1, padding=1, bias=False)\n",
        "    \n",
        "    self.l8 = nn.Conv2d(256, 128, 3, stride=1, padding=1, bias=False)\n",
        "    self.l9 = nn.MaxUnpool2d(2)\n",
        "    self.l10 = nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False)\n",
        "    self.l11 = nn.Conv2d(128, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.l12 = nn.MaxUnpool2d(2)\n",
        "    self.l13 = nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.l14 = nn.Conv2d(64, 3, 3, stride=1, padding=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y1 = self.l1(x)\n",
        "    y1 = self.l2(y1)\n",
        "    y2, i1 = self.l3(y1)\n",
        "    y2 = self.d(y2)\n",
        "    y2 = self.l4(y2)\n",
        "    y2 = self.l5(y2)\n",
        "    y3, i2 = self.l6(y2)\n",
        "    y3 = self.l7(y3)\n",
        "    y3 = self.l8(y3)\n",
        "    y3 = self.l9(y3, i2)\n",
        "    y3 = self.l10(y3)\n",
        "    y3 = self.l11(y3)\n",
        "    y3 = self.l12(y3, i1)\n",
        "    y3 = self.l13(y3)\n",
        "    y3 = self.l14(y3)\n",
        "    # y3 = torch.clamp(y3, 0, 1)\n",
        "    \n",
        "    return y3"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Dmc8833QH5",
        "outputId": "7b3ebf06-3375-40c3-cc20-9edc0faca056"
      },
      "source": [
        "model = Model()\n",
        "print(model)\n",
        "model.cuda()\n",
        "summary(model.cuda(), (3, 1024, 1024))\n",
        "# summary(model.cuda(), (3, 1024, 1024), batch_size=-1, device='cuda')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (l1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (d): Dropout(p=0.1, inplace=False)\n",
            "  (l4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (l7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l8): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l9): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "  (l10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l11): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l12): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "  (l13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (l14): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1       [-1, 64, 1024, 1024]           1,728\n",
            "            Conv2d-2       [-1, 64, 1024, 1024]          36,864\n",
            "         MaxPool2d-3  [[-1, 64, 512, 512], [-1, 64, 512, 512]]               0\n",
            "           Dropout-4         [-1, 64, 512, 512]               0\n",
            "            Conv2d-5        [-1, 128, 512, 512]          73,728\n",
            "            Conv2d-6        [-1, 128, 512, 512]         147,456\n",
            "         MaxPool2d-7  [[-1, 128, 256, 256], [-1, 128, 256, 256]]               0\n",
            "            Conv2d-8        [-1, 256, 256, 256]         294,912\n",
            "            Conv2d-9        [-1, 128, 256, 256]         294,912\n",
            "      MaxUnpool2d-10        [-1, 128, 512, 512]               0\n",
            "           Conv2d-11        [-1, 128, 512, 512]         147,456\n",
            "           Conv2d-12         [-1, 64, 512, 512]          73,728\n",
            "      MaxUnpool2d-13       [-1, 64, 1024, 1024]               0\n",
            "           Conv2d-14       [-1, 64, 1024, 1024]          36,864\n",
            "           Conv2d-15        [-1, 3, 1024, 1024]           1,728\n",
            "================================================================\n",
            "Total params: 1,109,376\n",
            "Trainable params: 1,109,376\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 12.00\n",
            "Forward/backward pass size (MB): 2684351016.00\n",
            "Params size (MB): 4.23\n",
            "Estimated Total Size (MB): 2684351032.23\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OgcUr1Bn8_7"
      },
      "source": [
        " \n",
        "# Calculate the one-dimensional Gaussian distribution vector\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        " \n",
        " \n",
        " # Create a Gaussian kernel, obtained by matrix multiplication of two one-dimensional Gaussian distribution vectors\n",
        " # You can set the channel parameter to expand to 3 channels\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        " \n",
        " \n",
        " # Calculate SSIM\n",
        " # Use the formula of SSIM directly, but when calculating the average value, instead of directly calculating the pixel average value, normalized Gaussian kernel convolution is used instead.\n",
        " # The formula Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y] is used when calculating variance and covariance .\n",
        " # As mentioned earlier, the above expectation operation is replaced by Gaussian kernel convolution.\n",
        "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
        "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
        "    if val_range is None:\n",
        "        if torch.max(img1) > 128:\n",
        "            max_val = 255\n",
        "        else:\n",
        "            max_val = 1\n",
        " \n",
        "        if torch.min(img1) < -0.5:\n",
        "            min_val = -1\n",
        "        else:\n",
        "            min_val = 0\n",
        "        L = max_val - min_val\n",
        "    else:\n",
        "        L = val_range\n",
        " \n",
        "    padd = 0\n",
        "    (_, channel, height, width) = img1.size()\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width)\n",
        "        window = create_window(real_size, channel=channel).to(img1.device)\n",
        " \n",
        "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
        " \n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        " \n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
        " \n",
        "    C1 = (0.01 * L) ** 2\n",
        "    C2 = (0.03 * L) ** 2\n",
        " \n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
        " \n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
        " \n",
        "    if size_average:\n",
        "        ret = ssim_map.mean()\n",
        "    else:\n",
        "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
        " \n",
        "    if full:\n",
        "        return ret, cs\n",
        "    return ret\n",
        " \n",
        " \n",
        " \n",
        "# Classes to re-use window\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.val_range = val_range\n",
        " \n",
        "        # Assume 1 channel for SSIM\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size)\n",
        " \n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        " \n",
        "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        " \n",
        "        return ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXrsIbTmRm4m"
      },
      "source": [
        "def mypsnr(img1, img2):\n",
        "    max_pixel = 1.0\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    psnr = 20 * math.log(max_pixel / math.sqrt(mse), 10)\n",
        "    \n",
        "    return psnr\n",
        "    \n",
        "def myssim(img1, img2):\n",
        "    #convert to tensor\n",
        "    img1 = torch.tensor(img1).cuda()\n",
        "    img2 = torch.tensor(img2).cuda()\n",
        "\n",
        "    #convert to variable\n",
        "    img1 = Variable(img1,  requires_grad=False)\n",
        "    img2 = Variable(img2, requires_grad = True)\n",
        "    \n",
        "    # ssim_value = pytorch_ssim.ssim(img1, img2)\n",
        "    ssim_value = ssim(img1, img2)\n",
        "    \n",
        "    return ssim_value.item()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQRnaF483QKF"
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimiser):\n",
        "    print(\"Training...\")\n",
        "    model.train()\n",
        "    \n",
        "    running_loss = 0.0\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimiser.zero_grad()\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "          print(\"Training batch: \", batch_idx)\n",
        "            \n",
        "    end_time = time.time()\n",
        "\n",
        "    running_loss /= len(train_loader)\n",
        "    print(\"Training loss: \", running_loss, \"Time: \", end_time-start_time, \"s\")\n",
        "        \n",
        "    return running_loss"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsOtp1QYSfEY"
      },
      "source": [
        "def val_epoch(model, val_loader, criterion):\n",
        "    print(\"Validating...\")\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      running_psnr = 0.0\n",
        "      running_ssim = 0.0\n",
        "\n",
        "      start_time = time.time()\n",
        "      \n",
        "      for batch_idx, (data, target) in enumerate(val_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          \n",
        "          outputs = model(data)\n",
        "          loss = criterion(outputs, target)\n",
        "          running_loss += loss.item()\n",
        "      \n",
        "          t,o = target.cpu().numpy(), outputs.cpu().numpy()\n",
        "          running_psnr += mypsnr(t, o)\n",
        "          running_ssim += myssim(t, o)\n",
        "          \n",
        "          if batch_idx % 50 == 0:\n",
        "            print(\"Validation batch: \", batch_idx)\n",
        "            \n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(val_loader)\n",
        "    print(\"Validation loss: \", running_loss, \"Time: \", end_time-start_time, \"s\")\n",
        "    running_psnr/=len(val_loader)\n",
        "    running_ssim/=len(val_loader)\n",
        "    print(\"PSNR: \", running_psnr, \"\\tSSIM: \", running_ssim)\n",
        "        \n",
        "    return running_loss, running_psnr, running_ssim"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjHyrv0m3QMP",
        "outputId": "8976723b-affa-450e-f67f-fa1a505ab342"
      },
      "source": [
        "n_epochs = 200\n",
        "model_no = 5\n",
        "\n",
        "learningRate = 0.00005\n",
        "weightDecay = 1e-5\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        # m.bias.data.fill_(0.01)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr = learningRate, weight_decay= weightDecay)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, mode='min', factor=0.7, patience=5)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0im1SN33QOb",
        "outputId": "b76def5b-b0d6-4711-e1f8-15fbe4840b86"
      },
      "source": [
        "Train_loss = []\n",
        "Val_loss = []\n",
        "PSNR = []\n",
        "SSIM = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Epoch \", i)\n",
        "\n",
        "    if path.exists('model_'+ str(model_no) + '_' + str(i)):\n",
        "      checkpoint = torch.load('model_' + str(model_no) + '_' + str(i))\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      # optimiser.load_state_dict(checkpoint['optimiser_state_dict'])\n",
        "  \n",
        "      Train_loss = checkpoint['tl']\n",
        "      Val_loss = checkpoint['vl']\n",
        "      PSNR = checkpoint['psnr']\n",
        "      SSIM = checkpoint['ssim']\n",
        "      \n",
        "      continue\n",
        "    print(\"LR: \", optimiser.param_groups[0]['lr'])\n",
        "    \n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimiser)\n",
        "    val_loss, p, s = val_epoch(model, val_loader, criterion)\n",
        "    \n",
        "    Train_loss.append(train_loss)\n",
        "    Val_loss.append(val_loss)\n",
        "    PSNR.append(p)\n",
        "    SSIM.append(s)\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimiser_state_dict': optimiser.state_dict(),\n",
        "            'tl': Train_loss,\n",
        "            'vl': Val_loss,\n",
        "            'psnr': PSNR,\n",
        "            'ssim': SSIM\n",
        "            }, 'model_' + str(model_no) + '_' + str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  0\n",
            "Epoch  1\n",
            "Epoch  2\n",
            "Epoch  3\n",
            "Epoch  4\n",
            "Epoch  5\n",
            "Epoch  6\n",
            "Epoch  7\n",
            "Epoch  8\n",
            "Epoch  9\n",
            "Epoch  10\n",
            "Epoch  11\n",
            "Epoch  12\n",
            "Epoch  13\n",
            "Epoch  14\n",
            "Epoch  15\n",
            "Epoch  16\n",
            "Epoch  17\n",
            "Epoch  18\n",
            "Epoch  19\n",
            "Epoch  20\n",
            "Epoch  21\n",
            "Epoch  22\n",
            "Epoch  23\n",
            "Epoch  24\n",
            "Epoch  25\n",
            "Epoch  26\n",
            "Epoch  27\n",
            "Epoch  28\n",
            "Epoch  29\n",
            "Epoch  30\n",
            "Epoch  31\n",
            "Epoch  32\n",
            "Epoch  33\n",
            "Epoch  34\n",
            "Epoch  35\n",
            "Epoch  36\n",
            "Epoch  37\n",
            "Epoch  38\n",
            "Epoch  39\n",
            "Epoch  40\n",
            "Epoch  41\n",
            "Epoch  42\n",
            "Epoch  43\n",
            "Epoch  44\n",
            "Epoch  45\n",
            "Epoch  46\n",
            "Epoch  47\n",
            "Epoch  48\n",
            "Epoch  49\n",
            "Epoch  50\n",
            "Epoch  51\n",
            "Epoch  52\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.004087499698925967 Time:  388.79089188575745 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003886408029939048 Time:  53.805938720703125 s\n",
            "PSNR:  25.113558812148348 \tSSIM:  0.6559211325645447\n",
            "Epoch  53\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.005281778449098056 Time:  381.7309989929199 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003939214163110592 Time:  30.088868379592896 s\n",
            "PSNR:  25.05461392971962 \tSSIM:  0.6476132363080979\n",
            "Epoch  54\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0036495568217651455 Time:  381.42081665992737 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037253825084189885 Time:  30.91421866416931 s\n",
            "PSNR:  25.36797914984462 \tSSIM:  0.66252959638834\n",
            "Epoch  55\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0035763456073436826 Time:  381.37772011756897 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036328981167753228 Time:  30.29351258277893 s\n",
            "PSNR:  25.52121228800234 \tSSIM:  0.6652361062169075\n",
            "Epoch  56\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003801209721932537 Time:  381.4358410835266 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004172444846190047 Time:  31.00507640838623 s\n",
            "PSNR:  24.730904847601767 \tSSIM:  0.6399484154582024\n",
            "Epoch  57\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0037131504462195155 Time:  381.4045753479004 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035722501773852856 Time:  30.666426420211792 s\n",
            "PSNR:  25.6009690444082 \tSSIM:  0.6706207558512688\n",
            "Epoch  58\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003963108863335947 Time:  381.5103907585144 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035894633176212663 Time:  31.133753061294556 s\n",
            "PSNR:  25.569209726505296 \tSSIM:  0.6713043585419655\n",
            "Epoch  59\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0038788719165313524 Time:  381.5548872947693 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036046511854510755 Time:  30.02518367767334 s\n",
            "PSNR:  25.53294583239943 \tSSIM:  0.67167753636837\n",
            "Epoch  60\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034494646721395837 Time:  381.42420625686646 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034926434625231193 Time:  30.032896995544434 s\n",
            "PSNR:  25.728686205214725 \tSSIM:  0.6785723480582238\n",
            "Epoch  61\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0036648233331288793 Time:  381.4886779785156 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035170520831889008 Time:  30.465619564056396 s\n",
            "PSNR:  25.677102701171272 \tSSIM:  0.6760731142759323\n",
            "Epoch  62\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0036639785108491195 Time:  381.4959752559662 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035282792746147607 Time:  30.984861612319946 s\n",
            "PSNR:  25.65969037012459 \tSSIM:  0.6773930877447129\n",
            "Epoch  63\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034148547654149295 Time:  381.47847056388855 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003479522891429951 Time:  30.463833808898926 s\n",
            "PSNR:  25.73824040390235 \tSSIM:  0.6823207634687424\n",
            "Epoch  64\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.00487326986676635 Time:  381.4006266593933 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003675707174115814 Time:  30.78904891014099 s\n",
            "PSNR:  25.386070217063228 \tSSIM:  0.6724437633156777\n",
            "Epoch  65\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034701487257189 Time:  381.3694725036621 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035738980773021467 Time:  30.168367385864258 s\n",
            "PSNR:  25.55402505462472 \tSSIM:  0.6778824710845948\n",
            "Epoch  66\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033725796089311188 Time:  381.5628538131714 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035541624168399723 Time:  30.826271295547485 s\n",
            "PSNR:  25.591030101440104 \tSSIM:  0.6808681410551071\n",
            "Epoch  67\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0035547022683567776 Time:  381.58721375465393 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037635635340120643 Time:  30.051748275756836 s\n",
            "PSNR:  25.23086008147155 \tSSIM:  0.6711029863357544\n",
            "Epoch  68\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003439662185319321 Time:  381.675341129303 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035153072766843253 Time:  30.08748722076416 s\n",
            "PSNR:  25.63627407785755 \tSSIM:  0.6837828674912453\n",
            "Epoch  69\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003600394068071182 Time:  381.4875593185425 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003484070004342357 Time:  30.89621067047119 s\n",
            "PSNR:  25.690024207586372 \tSSIM:  0.6816217458248138\n",
            "Epoch  70\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034875996433038382 Time:  381.65253496170044 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004403426149801817 Time:  30.382004261016846 s\n",
            "PSNR:  24.413437167771317 \tSSIM:  0.6825529727339744\n",
            "Epoch  71\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033437036524446738 Time:  381.4151313304901 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003425903055758681 Time:  30.895500421524048 s\n",
            "PSNR:  25.80257358257643 \tSSIM:  0.6867698603868484\n",
            "Epoch  72\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0036633434122813925 Time:  381.51115465164185 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035974160555633716 Time:  30.546545028686523 s\n",
            "PSNR:  25.489492945147713 \tSSIM:  0.6852940028905868\n",
            "Epoch  73\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003322160764291766 Time:  381.6186628341675 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037707302780472674 Time:  30.079242944717407 s\n",
            "PSNR:  25.203258540978254 \tSSIM:  0.6876646652817726\n",
            "Epoch  74\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033537329679711545 Time:  381.6084580421448 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033965167246060445 Time:  30.80876851081848 s\n",
            "PSNR:  25.872930851651343 \tSSIM:  0.6869910642504692\n",
            "Epoch  75\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034107676961684773 Time:  381.50930285453796 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003400095733377384 Time:  30.132628917694092 s\n",
            "PSNR:  25.827797212566907 \tSSIM:  0.6932989856600762\n",
            "Epoch  76\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033481723304612386 Time:  381.52183198928833 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004114479580312036 Time:  30.798046588897705 s\n",
            "PSNR:  24.721133435337656 \tSSIM:  0.6898448604345322\n",
            "Epoch  77\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034604201857109727 Time:  381.6153874397278 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003376634065207327 Time:  31.603801250457764 s\n",
            "PSNR:  25.873098759347023 \tSSIM:  0.6904465815424919\n",
            "Epoch  78\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032743324680268417 Time:  381.62415528297424 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.00347650806827005 Time:  30.740310192108154 s\n",
            "PSNR:  25.68313666114302 \tSSIM:  0.6960293039679527\n",
            "Epoch  79\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003326231619084865 Time:  381.8558955192566 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034059527113277 Time:  31.691070079803467 s\n",
            "PSNR:  25.83625227724495 \tSSIM:  0.692971096932888\n",
            "Epoch  80\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032959420142105954 Time:  381.7054879665375 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003514750584727153 Time:  30.715205907821655 s\n",
            "PSNR:  25.68449875892496 \tSSIM:  0.6943539088964462\n",
            "Epoch  81\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0034626994191239648 Time:  381.68553137779236 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004824083873827476 Time:  31.639193296432495 s\n",
            "PSNR:  23.875136816077443 \tSSIM:  0.661389334499836\n",
            "Epoch  82\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033018424091824272 Time:  381.593701839447 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033775784430326895 Time:  30.917040586471558 s\n",
            "PSNR:  25.863008697538135 \tSSIM:  0.6975871884822845\n",
            "Epoch  83\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.00318761808985073 Time:  381.54896569252014 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035515673705958763 Time:  30.454811096191406 s\n",
            "PSNR:  25.530756440978458 \tSSIM:  0.6954320707917213\n",
            "Epoch  84\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003597681541068596 Time:  381.69594621658325 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034004100317542906 Time:  31.105287075042725 s\n",
            "PSNR:  25.8114697885445 \tSSIM:  0.6975597929954529\n",
            "Epoch  85\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003190656030601531 Time:  381.6914336681366 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003345197852613637 Time:  31.69494938850403 s\n",
            "PSNR:  25.92357465313829 \tSSIM:  0.6955270141363143\n",
            "Epoch  86\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003231946682190028 Time:  381.63835549354553 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003399815377488267 Time:  30.89662194252014 s\n",
            "PSNR:  25.811098874444475 \tSSIM:  0.7024254614114761\n",
            "Epoch  87\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032621222814850624 Time:  381.6105718612671 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0032737030516727826 Time:  31.419367790222168 s\n",
            "PSNR:  26.048744777929592 \tSSIM:  0.702192844748497\n",
            "Epoch  88\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032946527079911903 Time:  381.62363266944885 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003346982125513023 Time:  31.01779294013977 s\n",
            "PSNR:  25.91769202177253 \tSSIM:  0.6998472222685814\n",
            "Epoch  89\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032011854065058286 Time:  381.5715696811676 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003324363668943988 Time:  31.751444578170776 s\n",
            "PSNR:  25.945314614545264 \tSSIM:  0.7026021519303322\n",
            "Epoch  90\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031760314573148207 Time:  381.3850257396698 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003559119796263985 Time:  30.818843841552734 s\n",
            "PSNR:  25.498060649576363 \tSSIM:  0.6989302751421929\n",
            "Epoch  91\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003301455140881444 Time:  381.6962192058563 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033148804398661015 Time:  30.105604887008667 s\n",
            "PSNR:  25.96206088728417 \tSSIM:  0.7053810319304467\n",
            "Epoch  92\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003219689486923016 Time:  381.47009086608887 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037306227860972284 Time:  30.684891939163208 s\n",
            "PSNR:  25.249594821754997 \tSSIM:  0.7025389519333839\n",
            "Epoch  93\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032319907237433653 Time:  381.6126046180725 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034265890876122285 Time:  30.662980794906616 s\n",
            "PSNR:  25.751598637312703 \tSSIM:  0.703727568089962\n",
            "Epoch  94\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003320650099449267 Time:  381.352219581604 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033983526172232815 Time:  31.062500953674316 s\n",
            "PSNR:  25.80193417079862 \tSSIM:  0.7042753100395203\n",
            "Epoch  95\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031164656737746555 Time:  381.52627778053284 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003424490133038489 Time:  31.651283025741577 s\n",
            "PSNR:  25.75068121348158 \tSSIM:  0.7068848249316215\n",
            "Epoch  96\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032502509844380256 Time:  381.56169533729553 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034022250738053117 Time:  30.44225001335144 s\n",
            "PSNR:  25.790195606149297 \tSSIM:  0.7065892544388771\n",
            "Epoch  97\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003290139064356481 Time:  381.433984041214 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034010438714176415 Time:  31.592283010482788 s\n",
            "PSNR:  25.79144498034188 \tSSIM:  0.7051760849356651\n",
            "Epoch  98\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003154905804531154 Time:  381.63482689857483 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033273675534292125 Time:  30.91266942024231 s\n",
            "PSNR:  25.918174706086415 \tSSIM:  0.6937823241949082\n",
            "Epoch  99\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032197012983306195 Time:  381.65387439727783 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0032221849240886514 Time:  30.433876752853394 s\n",
            "PSNR:  26.136025086455273 \tSSIM:  0.7056926333904266\n",
            "Epoch  100\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003158427183934691 Time:  381.43951416015625 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036323534362600186 Time:  31.26327681541443 s\n",
            "PSNR:  25.38352584181105 \tSSIM:  0.70772346585989\n",
            "Epoch  101\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003254068513851962 Time:  381.4547836780548 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003391552231187234 Time:  30.022659063339233 s\n",
            "PSNR:  25.812744088342246 \tSSIM:  0.7067569956183434\n",
            "Epoch  102\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031574689834997114 Time:  381.5033230781555 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003624559523887001 Time:  30.908812999725342 s\n",
            "PSNR:  25.38911709496064 \tSSIM:  0.7070911428332329\n",
            "Epoch  103\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0033404708778471104 Time:  381.5244851112366 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003464390407898463 Time:  31.153141260147095 s\n",
            "PSNR:  25.677169865512514 \tSSIM:  0.7079721561074257\n",
            "Epoch  104\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003094149501903303 Time:  381.7450144290924 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0032186794572044166 Time:  30.583524465560913 s\n",
            "PSNR:  26.152491696747397 \tSSIM:  0.7076083335280419\n",
            "Epoch  105\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032019822904476316 Time:  381.522097826004 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035538947777240537 Time:  31.072206020355225 s\n",
            "PSNR:  25.5226903912275 \tSSIM:  0.7074062570929527\n",
            "Epoch  106\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003170305926214496 Time:  381.723995923996 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003402372593554901 Time:  30.38914394378662 s\n",
            "PSNR:  25.780325188366977 \tSSIM:  0.7078349068760872\n",
            "Epoch  107\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0032395149003059485 Time:  381.59690499305725 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0032808872971509116 Time:  30.4027898311615 s\n",
            "PSNR:  26.025931788454756 \tSSIM:  0.7035904905200004\n",
            "Epoch  108\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031062238623053417 Time:  381.68787837028503 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034324664293671958 Time:  31.221747159957886 s\n",
            "PSNR:  25.722920625275492 \tSSIM:  0.707387008368969\n",
            "Epoch  109\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003173036210046121 Time:  381.6537549495697 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035247477114899086 Time:  30.061338186264038 s\n",
            "PSNR:  25.56871170130613 \tSSIM:  0.7081007626652718\n",
            "Epoch  110\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003174660976019368 Time:  381.5483570098877 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003450028387596831 Time:  31.171462059020996 s\n",
            "PSNR:  25.693294343261044 \tSSIM:  0.7102064302563668\n",
            "Epoch  111\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003138051243968221 Time:  381.5666058063507 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0031722505624929907 Time:  31.2533278465271 s\n",
            "PSNR:  26.251013516214254 \tSSIM:  0.7086971935629844\n",
            "Epoch  112\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031486349270198844 Time:  381.57095098495483 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0034690196011797525 Time:  31.11906385421753 s\n",
            "PSNR:  25.659149926425968 \tSSIM:  0.7095499607920647\n",
            "Epoch  113\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031501795884651073 Time:  381.457560300827 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0032393075867730658 Time:  31.210471630096436 s\n",
            "PSNR:  26.076502848907793 \tSSIM:  0.7066411811113358\n",
            "Epoch  114\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031707725761953042 Time:  381.61803698539734 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033981978379597423 Time:  30.475115299224854 s\n",
            "PSNR:  25.790772710083598 \tSSIM:  0.713562481701374\n",
            "Epoch  115\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003144329700826347 Time:  381.55758237838745 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0033849802709301 Time:  30.524713277816772 s\n",
            "PSNR:  25.818174471481885 \tSSIM:  0.709656468629837\n",
            "Epoch  116\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003102014234991657 Time:  381.5613360404968 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036100376272224823 Time:  30.33937978744507 s\n",
            "PSNR:  25.438101140971625 \tSSIM:  0.7097706973552704\n",
            "Epoch  117\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031499792185786645 Time:  381.4176516532898 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003536997974733822 Time:  30.66599178314209 s\n",
            "PSNR:  25.54560207341108 \tSSIM:  0.7118122753500938\n",
            "Epoch  118\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031341550848446786 Time:  381.57595348358154 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003519984828599263 Time:  31.05309557914734 s\n",
            "PSNR:  25.586353699927983 \tSSIM:  0.7121835055947304\n",
            "Epoch  119\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031022331343228873 Time:  381.5459015369415 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035037352470681073 Time:  30.706211805343628 s\n",
            "PSNR:  25.60902794152328 \tSSIM:  0.7092092436552048\n",
            "Epoch  120\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003228924115846894 Time:  381.41849994659424 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035036270154523664 Time:  30.89924454689026 s\n",
            "PSNR:  25.604680811089896 \tSSIM:  0.7100292655825615\n",
            "Epoch  121\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030727067291809363 Time:  381.64631819725037 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035819427482783796 Time:  30.671026468276978 s\n",
            "PSNR:  25.473676076408882 \tSSIM:  0.7118287163972855\n",
            "Epoch  122\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003111234471452917 Time:  381.72328329086304 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003486388916062424 Time:  30.116267919540405 s\n",
            "PSNR:  25.633733580607306 \tSSIM:  0.7140677562355995\n",
            "Epoch  123\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003284159970953624 Time:  381.58963561058044 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003504532753722742 Time:  31.114782094955444 s\n",
            "PSNR:  25.595610183192367 \tSSIM:  0.7109100210666657\n",
            "Epoch  124\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030649870837441994 Time:  381.5874538421631 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003502648415742442 Time:  30.003782272338867 s\n",
            "PSNR:  25.6123622567465 \tSSIM:  0.712407937347889\n",
            "Epoch  125\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003085199256820488 Time:  381.4832544326782 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036640924401581286 Time:  30.607770442962646 s\n",
            "PSNR:  25.3453194025818 \tSSIM:  0.7140126013755799\n",
            "Epoch  126\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031436727975415126 Time:  381.52747225761414 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035555283285793847 Time:  31.30576181411743 s\n",
            "PSNR:  25.501649121050935 \tSSIM:  0.7144971078634262\n",
            "Epoch  127\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003096825985612668 Time:  381.52215576171875 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003532723792013712 Time:  30.585301399230957 s\n",
            "PSNR:  25.538287050511094 \tSSIM:  0.7117785793542862\n",
            "Epoch  128\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031017059447913196 Time:  381.4607980251312 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0036707570144790223 Time:  31.26844358444214 s\n",
            "PSNR:  25.326155974264513 \tSSIM:  0.7139294186234474\n",
            "Epoch  129\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003106330267746671 Time:  381.4491603374481 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0040454480794142 Time:  30.4476318359375 s\n",
            "PSNR:  24.779991482999172 \tSSIM:  0.7142074820399285\n",
            "Epoch  130\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031237964399588236 Time:  381.83078718185425 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035131860119872725 Time:  29.918161869049072 s\n",
            "PSNR:  25.594725793609914 \tSSIM:  0.7141839647293091\n",
            "Epoch  131\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003072508367586124 Time:  381.6087472438812 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003972467282437719 Time:  30.958211660385132 s\n",
            "PSNR:  24.90058086617986 \tSSIM:  0.7148202201724052\n",
            "Epoch  132\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031051215232218965 Time:  381.66900396347046 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037901805076398887 Time:  30.179957389831543 s\n",
            "PSNR:  25.14389862314961 \tSSIM:  0.7113199436664581\n",
            "Epoch  133\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003181829219502106 Time:  381.5563564300537 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003770686432544608 Time:  30.73652219772339 s\n",
            "PSNR:  25.162051310299727 \tSSIM:  0.7129456052184104\n",
            "Epoch  134\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003118411267423653 Time:  381.7448914051056 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035794267285382377 Time:  31.13129210472107 s\n",
            "PSNR:  25.466648696452516 \tSSIM:  0.7145842203497886\n",
            "Epoch  135\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031024282904218124 Time:  381.5733938217163 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003906250078289304 Time:  30.593268871307373 s\n",
            "PSNR:  24.955826056164415 \tSSIM:  0.7139492398500442\n",
            "Epoch  136\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030443988201659523 Time:  381.5478539466858 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0044944869665778245 Time:  31.133790016174316 s\n",
            "PSNR:  24.239289183371724 \tSSIM:  0.7095370876789093\n",
            "Epoch  137\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031122854062050464 Time:  381.64105105400085 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0046109732682816686 Time:  31.2728111743927 s\n",
            "PSNR:  24.10391316012637 \tSSIM:  0.7066057780385018\n",
            "Epoch  138\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003195016556492192 Time:  381.65988206863403 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003936306229734328 Time:  30.349403142929077 s\n",
            "PSNR:  24.908654225307977 \tSSIM:  0.7109429404139519\n",
            "Epoch  139\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003043487379090948 Time:  381.64312052726746 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003897298166411929 Time:  30.553516149520874 s\n",
            "PSNR:  24.983685619132572 \tSSIM:  0.7121655583381653\n",
            "Epoch  140\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030592872817942407 Time:  381.72573232650757 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003802824452286586 Time:  30.509849071502686 s\n",
            "PSNR:  25.12976884863493 \tSSIM:  0.7150000321865082\n",
            "Epoch  141\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003094674872045289 Time:  381.6078019142151 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004117718917550519 Time:  31.14413857460022 s\n",
            "PSNR:  24.676007658130814 \tSSIM:  0.7173117774724961\n",
            "Epoch  142\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030871506172115916 Time:  381.656445980072 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037216146220453083 Time:  31.200389623641968 s\n",
            "PSNR:  25.241142493165068 \tSSIM:  0.7173833855986596\n",
            "Epoch  143\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031400269825462603 Time:  381.6182351112366 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0039170340134296565 Time:  31.129672288894653 s\n",
            "PSNR:  24.956988509944896 \tSSIM:  0.7133970496058464\n",
            "Epoch  144\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030616311256380867 Time:  381.7706038951874 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003948764118540567 Time:  30.88319993019104 s\n",
            "PSNR:  24.922494007825502 \tSSIM:  0.7126123678684234\n",
            "Epoch  145\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.003106027427493245 Time:  381.55901622772217 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003986430570657831 Time:  30.202885389328003 s\n",
            "PSNR:  24.8501405848518 \tSSIM:  0.7113492462038994\n",
            "Epoch  146\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031234289382882706 Time:  381.8122138977051 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004011817522114143 Time:  31.212621688842773 s\n",
            "PSNR:  24.832185749367166 \tSSIM:  0.7123363655805588\n",
            "Epoch  147\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030806855151786295 Time:  381.69178318977356 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0035615704717929476 Time:  29.695120811462402 s\n",
            "PSNR:  25.533538579270626 \tSSIM:  0.7135884994268418\n",
            "Epoch  148\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030582345087714203 Time:  381.7630281448364 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.0037792349941446444 Time:  29.911027669906616 s\n",
            "PSNR:  25.147360493203397 \tSSIM:  0.7121356153488159\n",
            "Epoch  149\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031610278570951777 Time:  381.7403721809387 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003921009323676117 Time:  30.879409313201904 s\n",
            "PSNR:  24.954666820194426 \tSSIM:  0.712635797560215\n",
            "Epoch  150\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0030458235475452964 Time:  381.4830992221832 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.003978111041651573 Time:  30.01306700706482 s\n",
            "PSNR:  24.878315377633854 \tSSIM:  0.7142711105942726\n",
            "Epoch  151\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n",
            "Training batch:  300\n",
            "Training batch:  400\n",
            "Training batch:  500\n",
            "Training batch:  600\n",
            "Training batch:  700\n",
            "Training loss:  0.0031066427314362954 Time:  381.48936200141907 s\n",
            "Validating...\n",
            "Validation batch:  0\n",
            "Validation batch:  50\n",
            "Validation loss:  0.004239264953357633 Time:  31.26554584503174 s\n",
            "PSNR:  24.55550982572889 \tSSIM:  0.7131870073080063\n",
            "Epoch  152\n",
            "LR:  5e-05\n",
            "Training...\n",
            "Training batch:  0\n",
            "Training batch:  100\n",
            "Training batch:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkZu27YO3QRQ",
        "outputId": "f036c0b4-7ea7-4cd8-8a80-545bae4f2c54"
      },
      "source": [
        "checkpoint = torch.load('AE/model_5_155')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimiser.load_state_dict(checkpoint['optimiser_state_dict'])\n",
        "\n",
        "PSNR = checkpoint['psnr']\n",
        "SSIM = checkpoint['ssim']\n",
        "\n",
        "print(PSNR)  \n",
        "print(SSIM)\n",
        "print(np.argmax(PSNR), np.max(PSNR))\n",
        "print(np.argmax(SSIM), np.max(SSIM))\n",
        "\n",
        "for i in range(156):\n",
        "  if PSNR[i]>26:\n",
        "    print(i, PSNR[i], SSIM[i])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-30.565415139425905, -26.46253641369647, -25.0797845124138, -24.120787228766893, -23.494197781299384, -22.393701837568198, -21.8003914346464, -19.917325460832807, -19.077667709215667, -17.69594463443075, -16.613640024000368, -15.957452968830554, -14.538428946515928, -13.806551430488014, -11.831229940827606, -10.39625203105006, -9.570058267771735, -5.9573417014697005, -2.9524351712121844, -1.5997595500282438, 1.5544628707788575, 3.2336339643333023, 4.922935554255063, 6.635804279485393, 8.493806856320104, 8.998151766877411, 4.599686928148439, 5.300740935173167, 5.723134432029325, 8.619687220558417, 9.678872803296635, 10.954322156995724, 10.940693434507894, 13.695514276248865, 14.679284278353043, 15.155377788875075, 15.925493951931548, 14.547681201300684, 18.503233472253385, 19.184767731754846, 20.089535219720002, 20.781206351757838, 21.876316268126796, 22.545528923684834, 23.871586499318553, 24.26445822902237, 24.725813276387026, 23.444321541321713, 24.535938077011437, 24.41838770348258, 24.983208169148433, 24.126895718599698, 25.113558812148348, 25.05461392971962, 25.36797914984462, 25.52121228800234, 24.730904847601767, 25.6009690444082, 25.569209726505296, 25.53294583239943, 25.728686205214725, 25.677102701171272, 25.65969037012459, 25.73824040390235, 25.386070217063228, 25.55402505462472, 25.591030101440104, 25.23086008147155, 25.63627407785755, 25.690024207586372, 24.413437167771317, 25.80257358257643, 25.489492945147713, 25.203258540978254, 25.872930851651343, 25.827797212566907, 24.721133435337656, 25.873098759347023, 25.68313666114302, 25.83625227724495, 25.68449875892496, 23.875136816077443, 25.863008697538135, 25.530756440978458, 25.8114697885445, 25.92357465313829, 25.811098874444475, 26.048744777929592, 25.91769202177253, 25.945314614545264, 25.498060649576363, 25.96206088728417, 25.249594821754997, 25.751598637312703, 25.80193417079862, 25.75068121348158, 25.790195606149297, 25.79144498034188, 25.918174706086415, 26.136025086455273, 25.38352584181105, 25.812744088342246, 25.38911709496064, 25.677169865512514, 26.152491696747397, 25.5226903912275, 25.780325188366977, 26.025931788454756, 25.722920625275492, 25.56871170130613, 25.693294343261044, 26.251013516214254, 25.659149926425968, 26.076502848907793, 25.790772710083598, 25.818174471481885, 25.438101140971625, 25.54560207341108, 25.586353699927983, 25.60902794152328, 25.604680811089896, 25.473676076408882, 25.633733580607306, 25.595610183192367, 25.6123622567465, 25.3453194025818, 25.501649121050935, 25.538287050511094, 25.326155974264513, 24.779991482999172, 25.594725793609914, 24.90058086617986, 25.14389862314961, 25.162051310299727, 25.466648696452516, 24.955826056164415, 24.239289183371724, 24.10391316012637, 24.908654225307977, 24.983685619132572, 25.12976884863493, 24.676007658130814, 25.241142493165068, 24.956988509944896, 24.922494007825502, 24.8501405848518, 24.832185749367166, 25.533538579270626, 25.147360493203397, 24.954666820194426, 24.878315377633854, 24.55550982572889, 24.407998509606603, 24.538926834679415, 24.522218444783253, 24.375723517486023]\n",
            "[0.003842437767067253, 0.0038338671249834987, 0.003830078907293739, 0.0038452795152324627, 0.0038571236641701035, 0.0038670719893531213, 0.003909074072232812, 0.003895877227834035, 0.0039945944303235595, 0.004141985719307968, 0.004179403338653174, 0.004178538945872105, 0.004347039154883845, 0.0040273696233634835, 0.0042559923157205045, 0.004540778052646601, 0.0036641772471921285, 0.00569118057966989, 0.004143854369285691, 0.004666095404681983, 0.010099772478060914, 0.014752005019181525, 0.021289427551673724, 0.031058944184333085, 0.037882797215133907, 0.04487889692652971, 0.015771819847577716, 0.022109913042513654, 0.02651587004773319, 0.041293255030177535, 0.050770579064264895, 0.06657816883176565, 0.07033178536221385, 0.10857980882748962, 0.13341000735759734, 0.15415944192558528, 0.18607342831790447, 0.17999088872224092, 0.25700958162546156, 0.2969434847682714, 0.3324414624273777, 0.38833405122160913, 0.46019645512104035, 0.5063172268867493, 0.5703038635849953, 0.5946930041909217, 0.6247152698040008, 0.5679958671331405, 0.6134793606400489, 0.6308747372031211, 0.6446523240208626, 0.6493644681572914, 0.6559211325645447, 0.6476132363080979, 0.66252959638834, 0.6652361062169075, 0.6399484154582024, 0.6706207558512688, 0.6713043585419655, 0.67167753636837, 0.6785723480582238, 0.6760731142759323, 0.6773930877447129, 0.6823207634687424, 0.6724437633156777, 0.6778824710845948, 0.6808681410551071, 0.6711029863357544, 0.6837828674912453, 0.6816217458248138, 0.6825529727339744, 0.6867698603868484, 0.6852940028905868, 0.6876646652817726, 0.6869910642504692, 0.6932989856600762, 0.6898448604345322, 0.6904465815424919, 0.6960293039679527, 0.692971096932888, 0.6943539088964462, 0.661389334499836, 0.6975871884822845, 0.6954320707917213, 0.6975597929954529, 0.6955270141363143, 0.7024254614114761, 0.702192844748497, 0.6998472222685814, 0.7026021519303322, 0.6989302751421929, 0.7053810319304467, 0.7025389519333839, 0.703727568089962, 0.7042753100395203, 0.7068848249316215, 0.7065892544388771, 0.7051760849356651, 0.6937823241949082, 0.7056926333904266, 0.70772346585989, 0.7067569956183434, 0.7070911428332329, 0.7079721561074257, 0.7076083335280419, 0.7074062570929527, 0.7078349068760872, 0.7035904905200004, 0.707387008368969, 0.7081007626652718, 0.7102064302563668, 0.7086971935629844, 0.7095499607920647, 0.7066411811113358, 0.713562481701374, 0.709656468629837, 0.7097706973552704, 0.7118122753500938, 0.7121835055947304, 0.7092092436552048, 0.7100292655825615, 0.7118287163972855, 0.7140677562355995, 0.7109100210666657, 0.712407937347889, 0.7140126013755799, 0.7144971078634262, 0.7117785793542862, 0.7139294186234474, 0.7142074820399285, 0.7141839647293091, 0.7148202201724052, 0.7113199436664581, 0.7129456052184104, 0.7145842203497886, 0.7139492398500442, 0.7095370876789093, 0.7066057780385018, 0.7109429404139519, 0.7121655583381653, 0.7150000321865082, 0.7173117774724961, 0.7173833855986596, 0.7133970496058464, 0.7126123678684234, 0.7113492462038994, 0.7123363655805588, 0.7135884994268418, 0.7121356153488159, 0.712635797560215, 0.7142711105942726, 0.7131870073080063, 0.7108377346396446, 0.7127793005108833, 0.7130051213502884, 0.7102917098999023]\n",
            "111 26.251013516214254\n",
            "142 0.7173833855986596\n",
            "87 26.048744777929592 0.702192844748497\n",
            "99 26.136025086455273 0.7056926333904266\n",
            "104 26.152491696747397 0.7076083335280419\n",
            "107 26.025931788454756 0.7035904905200004\n",
            "111 26.251013516214254 0.7086971935629844\n",
            "113 26.076502848907793 0.7066411811113358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQuvfdlr5fQT"
      },
      "source": [
        "def test_epoch(model, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = model(data)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_AE_5_111_Valid/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VVXjzIa5fLX",
        "outputId": "64c2e21b-586d-4410-d0d6-8145e64a974e"
      },
      "source": [
        "checkpoint = torch.load('AE/model_5_111')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "!mkdir Test_AE_5_111_Valid\n",
        "test_epoch(model, test_loader)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory Test_AE_5_111_Valid: File exists\n",
            "Testing...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}