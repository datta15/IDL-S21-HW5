{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW5_ESRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce1023d7e9594ea9b6a63ae0793bb1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff5fb2741407428b83c5480a21d43b13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe2fb09516564704b57c326df6b8d7bf",
              "IPY_MODEL_03416a00cd5a43cfbd1f96544870ea54",
              "IPY_MODEL_ba205fc88cf6492ba13745f8930a4050"
            ]
          }
        },
        "ff5fb2741407428b83c5480a21d43b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe2fb09516564704b57c326df6b8d7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c8ddabd05bd467b89643b922ebb2b03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_235b2edf794f44f592224c1a07a498b9"
          }
        },
        "03416a00cd5a43cfbd1f96544870ea54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10182dfe17474ee48cce9d025e2417e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fbd0ce2491d4439b152372ceb245b7f"
          }
        },
        "ba205fc88cf6492ba13745f8930a4050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe717b7fcdbe40faaafd3e4cffeb1a80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:15&lt;00:00, 36.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05e831d4b463411f873aee901ae248e9"
          }
        },
        "6c8ddabd05bd467b89643b922ebb2b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "235b2edf794f44f592224c1a07a498b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10182dfe17474ee48cce9d025e2417e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fbd0ce2491d4439b152372ceb245b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe717b7fcdbe40faaafd3e4cffeb1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05e831d4b463411f873aee901ae248e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrNY2wnX0NvD",
        "outputId": "efcbd8d6-77a4-4c48-9264-cf3f93b542f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omDG_h3-0anE",
        "outputId": "333b5bea-c1c6-4980-a90d-09a7618ddc8a"
      },
      "source": [
        "%cd gdrive/MyDrive/Colab\\ Notebooks/HW5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/HW5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1Baact5jMi",
        "outputId": "0bf246d3-7989-4ec1-b833-0e17d399542c"
      },
      "source": [
        "# !pip install numpy==1.16.2\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "# !pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install torch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchsummary \n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "!pip install pytorch_ssim\n",
        "import pytorch_ssim\n",
        "\n",
        "import math\n",
        "from math import exp\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "from os import path\n",
        "import gc\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.5\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting pytorch_ssim\n",
            "  Downloading pytorch_ssim-0.1.tar.gz (1.4 kB)\n",
            "Building wheels for collected packages: pytorch-ssim\n",
            "  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-py3-none-any.whl size=2026 sha256=3a2f32f52c49e5d23042273c653a0aa4faef9465afafdc8d58f299b18be4f783\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/20/09/ebf5e58bdf2560c760074cd140b7f7b0c882e216feabf1ae30\n",
            "Successfully built pytorch-ssim\n",
            "Installing collected packages: pytorch-ssim\n",
            "Successfully installed pytorch-ssim-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va8pOJY857Cj",
        "outputId": "39c0f6ef-12ec-4231-e714-8f98e1a100fb"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "num_workers = 2 if cuda else 0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWHF8iOT5-Og"
      },
      "source": [
        "transform = transforms.Compose([          \n",
        "            transforms.ToTensor(),\n",
        "            ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUkrx6Qw6Abt"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_in_folder, image_out_folder=None, transform=None):\n",
        "    self.image_in_folder = image_in_folder\n",
        "    self.image_in_paths = sorted(os.listdir(image_in_folder))\n",
        "    if image_out_folder:\n",
        "      self.image_out_folder = image_out_folder\n",
        "      self.image_out_paths = sorted(os.listdir(image_out_folder))\n",
        "    else:\n",
        "      self.image_out_folder = None\n",
        "    self.transform = transform\n",
        "            \n",
        "  def __getitem__(self, index):\n",
        "    x = Image.open(self.image_in_folder + self.image_in_paths[index])\n",
        "    x = x.convert('RGB')\n",
        "    if self.image_out_folder:\n",
        "        y = Image.open(self.image_out_folder + self.image_out_paths[index])\n",
        "        y = y.convert('RGB')\n",
        "    else:\n",
        "        y = self.image_in_paths[index]\n",
        "    if self.transform is not None:\n",
        "        x = self.transform(x)\n",
        "        if self.image_out_folder is not None:\n",
        "            y = self.transform(y)\n",
        "            i, j, h, w = transforms.RandomCrop.get_params(x, output_size=(min(x.size(1), 200), min(x.size(2), 200)))\n",
        "            x = transforms.functional.crop(x, i, j, h, w)\n",
        "            y = transforms.functional.crop(y, i*4, j*4, h*4, w*4)\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_in_paths)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4stj9Ju6CRt"
      },
      "source": [
        "train_x = 'HW5_IDLS21/HW5_train_val/DIV2K_train_LR_bicubic/X4/'\n",
        "train_y = 'HW5_IDLS21/HW5_train_val/DIV2K_train_HR/'\n",
        "train_dataset = MyDataset(train_x, train_y, transform)\n",
        "train_loader_args = dict(shuffle=True, batch_size=1, num_workers=num_workers, pin_memory=True, drop_last=True) \\\n",
        "                    if cuda else dict(shuffle=True, batch_size=1)\n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
        "del train_x, train_y\n",
        "\n",
        "val_x = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_LR_bicubic/X4/'\n",
        "val_y = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_HR/'\n",
        "val_dataset = MyDataset(val_x, val_y, transform)\n",
        "val_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "val_loader = DataLoader(val_dataset, **val_loader_args)\n",
        "del val_x, val_y\n",
        "\n",
        "# test_x_large = 'HW5_IDLS21/HW5_test/large_test/'\n",
        "test_x_large = 'HW5_IDLS21/HW5_test/structures/'\n",
        "test_dataset = MyDataset(test_x_large, None, transform)\n",
        "test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)\n",
        "del test_x_large"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s1Z1NNw6HRt",
        "outputId": "f73ae3bb-a64d-4db5-fd7b-9c9f27c41eb9"
      },
      "source": [
        "print(test_dataset.__getitem__(0)[0].size(), test_dataset.__getitem__(0)[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 161, 256]) img_001.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuJ-wUA8KPa"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.features = nn.Sequential(           \n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(512, 512, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.classifier(out)\n",
        "        out = out.view(out.size(0))\n",
        "        # out = nn. Sigmoid()(out.view(out.size(0)))\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ95xcXhW64i"
      },
      "source": [
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, channels = 64, growth_channels = 32, scale_ratio = 0.2):\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(channels + 0 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(channels + 1 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(channels + 2 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(channels + 3 * growth_channels, growth_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Conv2d(channels + 4 * growth_channels, channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.scale_ratio = scale_ratio\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                m.weight.data *= 0.1\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(torch.cat((x, conv1), dim=1))\n",
        "        conv3 = self.conv3(torch.cat((x, conv1, conv2), dim=1))\n",
        "        conv4 = self.conv4(torch.cat((x, conv1, conv2, conv3), dim=1))\n",
        "        conv5 = self.conv5(torch.cat((x, conv1, conv2, conv3, conv4), dim=1))\n",
        "\n",
        "        out = torch.add(conv5 * self.scale_ratio, x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResidualInResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, channels = 64, growth_channels = 32, scale_ratio = 0.2):\n",
        "        super(ResidualInResidualDenseBlock, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n",
        "        self.RDB2 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n",
        "        self.RDB3 = ResidualDenseBlock(channels, growth_channels, scale_ratio)\n",
        "\n",
        "        self.scale_ratio = scale_ratio\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "\n",
        "        out = torch.add(out * self.scale_ratio, x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz8rv2Zn-gf7"
      },
      "source": [
        "class SubpixelConvolutionLayer(nn.Module):\n",
        "    def __init__(self, channels = 64):\n",
        "        super(SubpixelConvolutionLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(channels, channels * 4, 3, 1, 1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.pixel_shuffle(out)\n",
        "        out = self.prelu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmq-JU1D9lin"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 9, 1, 4)\n",
        "           \n",
        "        trunk = []\n",
        "        for _ in range(16):\n",
        "            trunk += [ResidualInResidualDenseBlock(64, 32, 0.2)]\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 1, 1, bias=False)\n",
        "\n",
        "        subpixel_conv = []\n",
        "        for _ in range(2):\n",
        "            subpixel_conv += [SubpixelConvolutionLayer(64)]\n",
        "        self.subpixel_conv = nn.Sequential(*subpixel_conv)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, 9, 1, 4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(64, 3, 3, 1, 1)\n",
        "                \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        trunk = self.trunk(conv1)\n",
        "        conv2 = self.conv2(trunk)\n",
        "        out = conv1 + conv2\n",
        "        out = self.subpixel_conv(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = (out + 1) / 2\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sEmthlNCbzi"
      },
      "source": [
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True).eval()\n",
        "        self.model = nn.Sequential(*list(vgg19.features.children())[:35])\n",
        "        for _, parameters in self.model.named_parameters():\n",
        "            parameters.requires_grad = False\n",
        "        self.l1_loss = nn.L1Loss()\n",
        "\n",
        "    def forward(self, source, target, epoch):\n",
        "        vgg_loss = self.l1_loss(self.model(source), self.model(target))\n",
        "        pixel_loss = self.l1_loss(source, target)\n",
        "        if epoch < 15:\n",
        "          loss = pixel_loss\n",
        "        else:\n",
        "          loss = vgg_loss + 0.01 * pixel_loss\n",
        "        return loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2baI7iXj6TJB"
      },
      "source": [
        "# Calculate the one-dimensional Gaussian distribution vector\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        " \n",
        " \n",
        " # Create a Gaussian kernel, obtained by matrix multiplication of two one-dimensional Gaussian distribution vectors\n",
        " # You can set the channel parameter to expand to 3 channels\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        " \n",
        " \n",
        " # Calculate SSIM\n",
        " # Use the formula of SSIM directly, but when calculating the average value, instead of directly calculating the pixel average value, normalized Gaussian kernel convolution is used instead.\n",
        " # The formula Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y] is used when calculating variance and covariance .\n",
        " # As mentioned earlier, the above expectation operation is replaced by Gaussian kernel convolution.\n",
        "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
        "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
        "    if val_range is None:\n",
        "        if torch.max(img1) > 128:\n",
        "            max_val = 255\n",
        "        else:\n",
        "            max_val = 1\n",
        " \n",
        "        if torch.min(img1) < -0.5:\n",
        "            min_val = -1\n",
        "        else:\n",
        "            min_val = 0\n",
        "        L = max_val - min_val\n",
        "    else:\n",
        "        L = val_range\n",
        " \n",
        "    padd = 0\n",
        "    (_, channel, height, width) = img1.size()\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width)\n",
        "        window = create_window(real_size, channel=channel).to(img1.device)\n",
        " \n",
        "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
        " \n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        " \n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
        " \n",
        "    C1 = (0.01 * L) ** 2\n",
        "    C2 = (0.03 * L) ** 2\n",
        " \n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
        " \n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
        " \n",
        "    if size_average:\n",
        "        ret = ssim_map.mean()\n",
        "    else:\n",
        "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
        " \n",
        "    if full:\n",
        "        return ret, cs\n",
        "    return ret\n",
        " \n",
        " \n",
        " \n",
        "# Classes to re-use window\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.val_range = val_range\n",
        " \n",
        "        # Assume 1 channel for SSIM\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size)\n",
        " \n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        " \n",
        "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        " \n",
        "        return ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hSw3ir6cz-"
      },
      "source": [
        "def mypsnr(img1, img2):\n",
        "    max_pixel = 1.0\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    psnr = 20 * math.log(max_pixel / math.sqrt(mse), 10)\n",
        "    \n",
        "    return psnr\n",
        "    \n",
        "def myssim(img1, img2):\n",
        "    #convert to tensor\n",
        "    img1 = torch.tensor(img1).cuda()\n",
        "    img2 = torch.tensor(img2).cuda()\n",
        "\n",
        "    #convert to variable\n",
        "    img1 = Variable(img1,  requires_grad=False)\n",
        "    img2 = Variable(img2, requires_grad = True)\n",
        "    \n",
        "    # ssim_value = pytorch_ssim.ssim(img1, img2)\n",
        "    ssim_value = ssim(img1, img2)\n",
        "    \n",
        "    return ssim_value.item()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti3SUeGl671R"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbgcrB2S768U"
      },
      "source": [
        "def train_epoch(netG, netD, train_loader, criterion, content_criterion, optimiserG, optimiserD, results, epoch):\n",
        "  print(\"Training...\")\n",
        "  netG.train()\n",
        "  netD.train()\n",
        "  running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    g_update_first = True\n",
        "    batch_size = data.size(0)\n",
        "    running_results['batch_sizes'] += batch_size\n",
        "    \n",
        "    real_label = torch.ones((batch_size, 1)).cuda()\n",
        "    fake_label = torch.zeros((batch_size, 1)).cuda()\n",
        "\n",
        "    netD.zero_grad()\n",
        "    fake_img = netG(data)\n",
        "    fake_out = netD(fake_img.detach()).unsqueeze(0)\n",
        "    real_out = netD(target).unsqueeze(0)\n",
        "    d_loss_real = criterion(real_out - fake_out.mean(), real_label)\n",
        "    d_loss_fake = criterion(fake_out - real_out.mean(), fake_label)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    d_loss.backward()\n",
        "    optimiserD.step()\n",
        "\n",
        "    if epoch % 2 == 1 or epoch > 15:\n",
        "      del fake_img\n",
        "      del fake_out\n",
        "      del real_out\n",
        "      torch.cuda.empty_cache()    \n",
        "      netG.zero_grad()\n",
        "      real_out = netD(target.detach()).unsqueeze(0)\n",
        "      fake_img = netG(data)\n",
        "      fake_out = netD(fake_img).unsqueeze(0)\n",
        "      g_loss_real = criterion(real_out - fake_out.mean(), fake_label)\n",
        "      g_loss_fake = criterion(fake_out - real_out.mean(), real_label)\n",
        "      if epoch < 10:\n",
        "        g_loss = content_criterion(fake_img, target, epoch)\n",
        "      else:\n",
        "        g_loss = content_criterion(fake_img, target, epoch) + 0.005 * (g_loss_fake)\n",
        "      g_loss.backward()\n",
        "      optimiserG.step()\n",
        "    else:\n",
        "      g_loss = None\n",
        "\n",
        "    # loss for current batch before optimization \n",
        "    fake_img = netG(data)\n",
        "    fake_out = netD(fake_img)\n",
        "    \n",
        "    if g_loss:\n",
        "      running_results['g_loss'] += g_loss.item() * batch_size\n",
        "    running_results['d_loss'] += d_loss.item() * batch_size\n",
        "    running_results['d_score'] += nn.Sigmoid()(real_out).item() * batch_size\n",
        "    running_results['g_score'] += nn.Sigmoid()(fake_out).item() * batch_size\n",
        "    \n",
        "    del fake_img\n",
        "    del fake_out\n",
        "    del real_out\n",
        "    torch.cuda.empty_cache()\n",
        "    if (batch_idx+1) % 200 == 0:\n",
        "      print(\"\\tBatch: %d Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\" % (\n",
        "          batch_idx + 1,\n",
        "          running_results['d_loss'] / running_results['batch_sizes'],\n",
        "          running_results['g_loss'] / running_results['batch_sizes'],\n",
        "          running_results['d_score'] / running_results['batch_sizes'],\n",
        "          running_results['g_score'] / running_results['batch_sizes']))\n",
        "      \n",
        "  end_time = time.time()\n",
        "\n",
        "  print(\"Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f Time: %.4f\" % (\n",
        "      running_results['d_loss'] / running_results['batch_sizes'],\n",
        "      running_results['g_loss'] / running_results['batch_sizes'],\n",
        "      running_results['d_score'] / running_results['batch_sizes'],\n",
        "      running_results['g_score'] / running_results['batch_sizes'],\n",
        "      end_time - start_time))\n",
        "  \n",
        "  results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "  results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "  results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "  results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quISEASACC7j"
      },
      "source": [
        "def val_epoch(netG, netD, val_loader, results):\n",
        "    print(\"Validating...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_results = {'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "      for batch_idx, (data, target) in enumerate(val_loader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        batch_size = data.size(0)\n",
        "        val_results['batch_sizes'] += batch_size\n",
        "        fake_img = netG(data)\n",
        "        t,o = target.cpu().numpy(), fake_img.cpu().numpy()\n",
        "\n",
        "        val_results['ssim'] += myssim(t, o)\n",
        "        val_results['psnr'] += mypsnr(t, o)\n",
        "\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    print(\"PSNR: %.4f dB SSIM: %.4f Time: %.4f\" % (\n",
        "          val_results['psnr']/val_results['batch_sizes'], \n",
        "          val_results['ssim']/val_results['batch_sizes'],\n",
        "          end_time - start_time))\n",
        "    \n",
        "    results['psnr'].append(val_results['psnr'] / val_results['batch_sizes'])\n",
        "    results['ssim'].append(val_results['ssim'] / val_results['batch_sizes'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ce1023d7e9594ea9b6a63ae0793bb1e7",
            "ff5fb2741407428b83c5480a21d43b13",
            "fe2fb09516564704b57c326df6b8d7bf",
            "03416a00cd5a43cfbd1f96544870ea54",
            "ba205fc88cf6492ba13745f8930a4050",
            "6c8ddabd05bd467b89643b922ebb2b03",
            "235b2edf794f44f592224c1a07a498b9",
            "10182dfe17474ee48cce9d025e2417e2",
            "8fbd0ce2491d4439b152372ceb245b7f",
            "fe717b7fcdbe40faaafd3e4cffeb1a80",
            "05e831d4b463411f873aee901ae248e9"
          ]
        },
        "id": "ERs99FIEJNcO",
        "outputId": "a7bd6794-88df-44e8-b674-1e6cc2a21b55"
      },
      "source": [
        "n_epochs = 200\n",
        "model_no = 5\n",
        "\n",
        "learningRate = 0.0002\n",
        "weightDecay = 1e-5\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "netG = Generator()\n",
        "netD = Discriminator()\n",
        "\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "\n",
        "# netG  # convert to half precision\n",
        "# for layer in netG.modules():\n",
        "#   if isinstance(layer, nn.BatchNorm2d):\n",
        "#     layer.float()\n",
        "\n",
        "# netD  # convert to half precision\n",
        "# for layer in netD.modules():\n",
        "#   if isinstance(layer, nn.BatchNorm2d):\n",
        "#     layer.float()\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        # m.bias.data.fill_(0.01)\n",
        "\n",
        "netG.apply(init_weights)\n",
        "netD.apply(init_weights)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)\n",
        "\n",
        "content_criterion = ContentLoss()\n",
        "content_criterion.to(device)\n",
        "\n",
        "optimiserG = optim.Adam(netG.parameters(), lr=learningRate)\n",
        "optimiserD = optim.Adam(netD.parameters(), lr=learningRate)\n",
        "\n",
        "schedulerG = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiserG, mode='min', factor=0.7, patience=5)\n",
        "schedulerD = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiserD, mode='min', factor=0.7, patience=5)\n",
        "\n",
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce1023d7e9594ea9b6a63ae0793bb1e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYFtuYCc6_12"
      },
      "source": [
        "for i in range(n_epochs):\n",
        "    print(\"Epoch \", i)\n",
        "\n",
        "    if path.exists('ESRGAN/model_'+ str(model_no) + '_' + str(i)) and i <= 34:\n",
        "      checkpoint = torch.load('ESRGAN/model_' + str(model_no) + '_' + str(i))\n",
        "      netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "      netD.load_state_dict(checkpoint['netD_state_dict'])\n",
        "      # optimiserG.load_state_dict(checkpoint['optimiserG_state_dict'])\n",
        "      optimiserD.load_state_dict(checkpoint['optimiserD_state_dict'])\n",
        "      results = checkpoint['results']\n",
        "      continue\n",
        "\n",
        "    print(\"LRs: \", optimiserG.param_groups[0]['lr'], optimiserD.param_groups[0]['lr'])\n",
        "    \n",
        "    train_epoch(netG, netD, train_loader, criterion, content_criterion, optimiserG, optimiserD, results, i)\n",
        "    val_epoch(netG, netD, val_loader, results)\n",
        "    \n",
        "    torch.save({\n",
        "            'epoch': i,\n",
        "            'netG_state_dict': netG.state_dict(),\n",
        "            'netD_state_dict': netD.state_dict(),\n",
        "            'optimiserG_state_dict': optimiserG.state_dict(),\n",
        "            'optimiserD_state_dict': optimiserD.state_dict(),\n",
        "            'results': results,\n",
        "            }, 'ESRGAN/model_' + str(model_no) + '_' + str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WXEggd8CalY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93d4783-efaf-4b17-e56b-1eeb32cfdf3d"
      },
      "source": [
        "checkpoint = torch.load('ESRGAN/model_0_50')\n",
        "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "\n",
        "results = checkpoint['results']      \n",
        "PSNR = results['psnr']\n",
        "SSIM = results['ssim']\n",
        "\n",
        "print(PSNR)  \n",
        "print(SSIM)\n",
        "print(np.argmax(PSNR), np.max(PSNR))\n",
        "print(np.argmax(SSIM), np.max(SSIM))\n",
        "print(len(val_dataset))\n",
        "for i in range(51):\n",
        "  if PSNR[i]/100>26:\n",
        "    print(i, PSNR[i]/100, SSIM[i]/100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[938.4579861790623, 918.1721030258301, 923.3254388711752, 945.1728130797482, 2172.7827826414173, 1822.11284678086, 2114.126999214991, 2100.362786829923, 2054.799515482883, 2313.1777694564175, 2206.4353585266335, 2233.97356238686, 2230.349149250878, 2335.6012350101655, 2335.2978297062596, 2349.5833839647994, 2338.848333843356, 2408.7866120730764, 2641.892240826633, 2483.9406617086192, 2616.9224354263692, 2560.2344034466983, 2587.613063785094, 2639.1941779261765, 2622.321065059593, 2618.7346040650423, 2592.310040564089, 2475.6834628347515, 2605.675434439386, 2569.345351935207, 2573.167169851266, 2670.458547961446, 2572.3091429619626, 2508.7853142491526, 2583.4332383651417, 2610.5936385471896, 2542.8614056555534, 2594.3213105622845, 2538.763627965324, 2579.4546045148113, 2537.349414273007, 2484.1497821189346, 2465.6867796501756, 2333.024182433196, 2539.8579378086597, 2568.7035012898878, 2472.732772833576, 2397.21221423795, 2490.5620101784716, 2485.8942675812123, 2534.448864169928]\n",
            "[2.8946046293713152, 2.9373811041004956, 2.659958888310939, 9.094880861230195, 54.0545651614666, 54.402260169386864, 54.55960327386856, 61.34686666727066, 62.422327902168036, 62.32040926814079, 66.04503691196442, 67.19983583688736, 65.36362418532372, 65.17081108689308, 63.013924300670624, 66.88454931974411, 61.919332444667816, 65.36691197752953, 72.35028323531151, 67.29474028944969, 72.16380873322487, 70.8582593202591, 71.89325967431068, 71.8188407421112, 71.79789435863495, 72.88407135009766, 70.14641132950783, 70.90183272957802, 71.7256327867508, 70.47386920452118, 70.1444725394249, 73.21008357405663, 70.23336732387543, 72.90959805250168, 69.55628278851509, 71.88454605638981, 71.63661760091782, 71.84917625784874, 70.16662749648094, 70.58318275213242, 70.61265662312508, 67.40671283006668, 66.22920805215836, 63.17021432518959, 67.47158566117287, 69.48852124810219, 67.5062535405159, 64.01282578706741, 66.21076481044292, 66.83369493484497, 66.35721337795258]\n",
            "31 2670.458547961446\n",
            "31 73.21008357405663\n",
            "100\n",
            "18 26.41892240826633 0.7235028323531151\n",
            "20 26.169224354263694 0.7216380873322487\n",
            "23 26.391941779261764 0.718188407421112\n",
            "24 26.22321065059593 0.7179789435863495\n",
            "25 26.18734604065042 0.7288407135009766\n",
            "28 26.056754344393863 0.7172563278675079\n",
            "31 26.70458547961446 0.7321008357405663\n",
            "35 26.105936385471896 0.7188454605638981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaQmnMRv6Pd6"
      },
      "source": [
        "def test_epoch(netG, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = netG(data)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_ESRGAN_0_31_Structures/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_ZwbdSTPCY"
      },
      "source": [
        "def test_epoch(netG, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        size = (data.size(2)*4, data.size(3)*4)\n",
        "        data_size = (200, int(data.size(3)/data.size(2)*200))\n",
        "        if data.size(3) > data.size(2):\n",
        "          data_size = (int(data.size(2)/data.size(3)*200), 200)\n",
        "        print(data_size)\n",
        "        data = F.interpolate(data, data_size)\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = netG(data)\n",
        "        fake_img = F.interpolate(fake_img, size)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_ESRGAN_0_31_Scaled200_4/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf1zwJqiCL_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adcee86-a27f-4c66-8c1c-78a57a8468f1"
      },
      "source": [
        "checkpoint = torch.load('ESRGAN/model_0_31')\n",
        "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "!mkdir Test_ESRGAN_0_31_Structures\n",
        "test_epoch(netG, test_loader)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}