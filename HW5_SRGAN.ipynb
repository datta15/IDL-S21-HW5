{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adfbeaeff4104ca5911bab5745755753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48354e3e8c9b41a39dc927f68753cdcd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32467df61df347929a955083bbab4d68",
              "IPY_MODEL_230a092b86194daa852e005953536e4f",
              "IPY_MODEL_256ff7d20d344c4bbece061b0b74bf40"
            ]
          }
        },
        "48354e3e8c9b41a39dc927f68753cdcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32467df61df347929a955083bbab4d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9c792e331da4a02a856adffd78d7726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad0a6d4338404f568efb86af40dc32fa"
          }
        },
        "230a092b86194daa852e005953536e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9c0b2b2009345218e1bbab93e4422d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a1b390b1e654f9a8ef0952ce3be064d"
          }
        },
        "256ff7d20d344c4bbece061b0b74bf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fad54d6fa6dc465a88974f657254545e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:10&lt;00:00, 67.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9f998cbfa3f4e3f86ea8695fa97accf"
          }
        },
        "e9c792e331da4a02a856adffd78d7726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad0a6d4338404f568efb86af40dc32fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9c0b2b2009345218e1bbab93e4422d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a1b390b1e654f9a8ef0952ce3be064d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fad54d6fa6dc465a88974f657254545e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9f998cbfa3f4e3f86ea8695fa97accf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrNY2wnX0NvD",
        "outputId": "8612b745-90fd-43e4-bf4b-d75c78413ce1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omDG_h3-0anE",
        "outputId": "ce516559-57f0-4c0d-ba37-51054f9a4d9c"
      },
      "source": [
        "%cd gdrive/MyDrive/Colab\\ Notebooks/HW5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/HW5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1Baact5jMi",
        "outputId": "314e3f6e-4607-4eaf-d799-090905e217e6"
      },
      "source": [
        "# !pip install numpy==1.16.2\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "# !pip install torch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchsummary \n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "!pip install pytorch_ssim\n",
        "import pytorch_ssim\n",
        "\n",
        "import math\n",
        "from math import exp\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "from os import path\n",
        "import gc\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.5\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting pytorch_ssim\n",
            "  Downloading pytorch_ssim-0.1.tar.gz (1.4 kB)\n",
            "Building wheels for collected packages: pytorch-ssim\n",
            "  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-py3-none-any.whl size=2026 sha256=1bb7e3241b2321720f980b661fc08a72ce3c7029fdaa5cb059220bebe24438d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/20/09/ebf5e58bdf2560c760074cd140b7f7b0c882e216feabf1ae30\n",
            "Successfully built pytorch-ssim\n",
            "Installing collected packages: pytorch-ssim\n",
            "Successfully installed pytorch-ssim-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va8pOJY857Cj",
        "outputId": "4e3c6e7e-7bf3-4179-8537-468a9f4a1f8e"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "num_workers = 2 if cuda else 0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWHF8iOT5-Og"
      },
      "source": [
        "transform = transforms.Compose([          \n",
        "            transforms.ToTensor(),\n",
        "            ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUkrx6Qw6Abt"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_in_folder, image_out_folder=None, transform=None):\n",
        "    self.image_in_folder = image_in_folder\n",
        "    self.image_in_paths = sorted(os.listdir(image_in_folder))\n",
        "    if image_out_folder:\n",
        "      self.image_out_folder = image_out_folder\n",
        "      self.image_out_paths = sorted(os.listdir(image_out_folder))\n",
        "    else:\n",
        "      self.image_out_folder = None\n",
        "    self.transform = transform\n",
        "            \n",
        "  def __getitem__(self, index):\n",
        "    x = Image.open(self.image_in_folder + self.image_in_paths[index])\n",
        "    x = x.convert('RGB')\n",
        "    if self.image_out_folder:\n",
        "        y = Image.open(self.image_out_folder + self.image_out_paths[index])\n",
        "        y = y.convert('RGB')\n",
        "    else:\n",
        "        y = self.image_in_paths[index]\n",
        "    if self.transform is not None:\n",
        "        x = self.transform(x)\n",
        "        if self.image_out_folder is not None:\n",
        "            y = self.transform(y)\n",
        "            i, j, h, w = transforms.RandomCrop.get_params(x, output_size=(min(x.size(1), 200), min(x.size(2), 200)))\n",
        "            x = transforms.functional.crop(x, i, j, h, w)\n",
        "            y = transforms.functional.crop(y, i*4, j*4, h*4, w*4)\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_in_paths)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4stj9Ju6CRt"
      },
      "source": [
        "train_x = 'HW5_IDLS21/HW5_train_val/DIV2K_train_LR_bicubic/X4/'\n",
        "train_y = 'HW5_IDLS21/HW5_train_val/DIV2K_train_HR/'\n",
        "train_dataset = MyDataset(train_x, train_y, transform)\n",
        "train_loader_args = dict(shuffle=True, batch_size=1, num_workers=num_workers, pin_memory=True, drop_last=True) \\\n",
        "                    if cuda else dict(shuffle=True, batch_size=1)\n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
        "del train_x, train_y\n",
        "\n",
        "val_x = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_LR_bicubic/X4/'\n",
        "val_y = 'HW5_IDLS21/HW5_train_val/DIV2K_valid_HR/'\n",
        "val_dataset = MyDataset(val_x, val_y, transform)\n",
        "val_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "val_loader = DataLoader(val_dataset, **val_loader_args)\n",
        "del val_x, val_y\n",
        "\n",
        "# test_x_large = 'HW5_IDLS21/HW5_test/large_test/'\n",
        "test_x_large = 'HW5_IDLS21/HW5_test/structures/'\n",
        "test_dataset = MyDataset(test_x_large, None, transform)\n",
        "test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) \\\n",
        "                    if cuda else dict(shuffle=False, batch_size=1)\n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)\n",
        "del test_x_large"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s1Z1NNw6HRt",
        "outputId": "9c2ba0ae-2299-45ae-f762-82e51ab3483b"
      },
      "source": [
        "print(test_dataset.__getitem__(0)[0].size(), test_dataset.__getitem__(0)[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 120, 125]) baboon.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuJ-wUA8KPa"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(512, 512, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.classifier(out)\n",
        "        out = nn. Sigmoid()(out.view(out.size(0)))\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T9vvsCn-gUV"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels = 64):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, 1, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.prelu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += x\n",
        "\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz8rv2Zn-gf7"
      },
      "source": [
        "class SubpixelConvolutionLayer(nn.Module):\n",
        "    def __init__(self, channels = 64):\n",
        "        super(SubpixelConvolutionLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(channels, channels * 4, 3, 1, 1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.pixel_shuffle(out)\n",
        "        out = self.prelu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmq-JU1D9lin"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 9, 1, 4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "\n",
        "        trunk = []\n",
        "        for _ in range(16):\n",
        "            trunk += [ResidualBlock(64)]\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "\n",
        "        subpixel_conv = []\n",
        "        for _ in range(2):\n",
        "            subpixel_conv += [SubpixelConvolutionLayer(64)]\n",
        "        self.subpixel_conv = nn.Sequential(*subpixel_conv)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 3, 9, 1, 4),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        trunk = self.trunk(conv1)\n",
        "        conv2 = self.conv2(trunk)\n",
        "        out = conv1 + conv2\n",
        "        out = self.subpixel_conv(out)\n",
        "        out = self.conv3(out)\n",
        "        out = (out + 1) / 2\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sEmthlNCbzi"
      },
      "source": [
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True).eval()\n",
        "        self.model = nn.Sequential(*list(vgg19.features.children())[:36])\n",
        "        for _, parameters in self.model.named_parameters():\n",
        "            parameters.requires_grad = False\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        vgg_loss = self.mse_loss(self.model(source), self.model(target))\n",
        "        mse_loss = self.mse_loss(source, target)\n",
        "        loss = mse_loss + 0.006 * vgg_loss\n",
        "        return loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYtZqJ9I1U8Y",
        "outputId": "9afca06f-b6ec-402a-bd2f-f4bcdcd6e381"
      },
      "source": [
        "netD = Discriminator()\n",
        "print(netD)\n",
        "netD.cuda()\n",
        "summary(netD.cuda(), (3, 128, 128))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "    (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 64, 64]             128\n",
            "         LeakyReLU-5           [-1, 64, 64, 64]               0\n",
            "            Conv2d-6          [-1, 128, 64, 64]          73,728\n",
            "       BatchNorm2d-7          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-8          [-1, 128, 64, 64]               0\n",
            "            Conv2d-9          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-10          [-1, 128, 32, 32]             256\n",
            "        LeakyReLU-11          [-1, 128, 32, 32]               0\n",
            "           Conv2d-12          [-1, 256, 32, 32]         294,912\n",
            "      BatchNorm2d-13          [-1, 256, 32, 32]             512\n",
            "        LeakyReLU-14          [-1, 256, 32, 32]               0\n",
            "           Conv2d-15          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-16          [-1, 256, 16, 16]             512\n",
            "        LeakyReLU-17          [-1, 256, 16, 16]               0\n",
            "           Conv2d-18          [-1, 512, 16, 16]       1,179,648\n",
            "      BatchNorm2d-19          [-1, 512, 16, 16]           1,024\n",
            "        LeakyReLU-20          [-1, 512, 16, 16]               0\n",
            "           Conv2d-21            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-22            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-23            [-1, 512, 8, 8]               0\n",
            "AdaptiveAvgPool2d-24            [-1, 512, 1, 1]               0\n",
            "           Conv2d-25           [-1, 1024, 1, 1]         525,312\n",
            "        LeakyReLU-26           [-1, 1024, 1, 1]               0\n",
            "           Conv2d-27              [-1, 1, 1, 1]           1,025\n",
            "================================================================\n",
            "Total params: 5,213,569\n",
            "Trainable params: 5,213,569\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 48.27\n",
            "Params size (MB): 19.89\n",
            "Estimated Total Size (MB): 68.35\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGTp-gQH1i85",
        "outputId": "e6ed0c10-1aea-4cb1-adc4-d54f62c7ede6"
      },
      "source": [
        "netG = Generator()\n",
        "print(netG)\n",
        "netG.cuda()\n",
        "summary(netG.cuda(), (3, 128, 128))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "    (1): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (trunk): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (6): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (7): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (8): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (9): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (10): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (11): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (12): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (13): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (14): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (15): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (subpixel_conv): Sequential(\n",
            "    (0): SubpixelConvolutionLayer(\n",
            "      (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (1): SubpixelConvolutionLayer(\n",
            "      (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(64, 3, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]          15,616\n",
            "             PReLU-2         [-1, 64, 128, 128]               1\n",
            "            Conv2d-3         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-4         [-1, 64, 128, 128]             128\n",
            "             PReLU-5         [-1, 64, 128, 128]               1\n",
            "            Conv2d-6         [-1, 64, 128, 128]          36,864\n",
            "       BatchNorm2d-7         [-1, 64, 128, 128]             128\n",
            "     ResidualBlock-8         [-1, 64, 128, 128]               0\n",
            "            Conv2d-9         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-10         [-1, 64, 128, 128]             128\n",
            "            PReLU-11         [-1, 64, 128, 128]               1\n",
            "           Conv2d-12         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-13         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-14         [-1, 64, 128, 128]               0\n",
            "           Conv2d-15         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-16         [-1, 64, 128, 128]             128\n",
            "            PReLU-17         [-1, 64, 128, 128]               1\n",
            "           Conv2d-18         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-19         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-20         [-1, 64, 128, 128]               0\n",
            "           Conv2d-21         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-22         [-1, 64, 128, 128]             128\n",
            "            PReLU-23         [-1, 64, 128, 128]               1\n",
            "           Conv2d-24         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-25         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-26         [-1, 64, 128, 128]               0\n",
            "           Conv2d-27         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-28         [-1, 64, 128, 128]             128\n",
            "            PReLU-29         [-1, 64, 128, 128]               1\n",
            "           Conv2d-30         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-31         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-32         [-1, 64, 128, 128]               0\n",
            "           Conv2d-33         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-34         [-1, 64, 128, 128]             128\n",
            "            PReLU-35         [-1, 64, 128, 128]               1\n",
            "           Conv2d-36         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-37         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-38         [-1, 64, 128, 128]               0\n",
            "           Conv2d-39         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-40         [-1, 64, 128, 128]             128\n",
            "            PReLU-41         [-1, 64, 128, 128]               1\n",
            "           Conv2d-42         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-43         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-44         [-1, 64, 128, 128]               0\n",
            "           Conv2d-45         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-46         [-1, 64, 128, 128]             128\n",
            "            PReLU-47         [-1, 64, 128, 128]               1\n",
            "           Conv2d-48         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-49         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-50         [-1, 64, 128, 128]               0\n",
            "           Conv2d-51         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-52         [-1, 64, 128, 128]             128\n",
            "            PReLU-53         [-1, 64, 128, 128]               1\n",
            "           Conv2d-54         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-55         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-56         [-1, 64, 128, 128]               0\n",
            "           Conv2d-57         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-58         [-1, 64, 128, 128]             128\n",
            "            PReLU-59         [-1, 64, 128, 128]               1\n",
            "           Conv2d-60         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-61         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-62         [-1, 64, 128, 128]               0\n",
            "           Conv2d-63         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-64         [-1, 64, 128, 128]             128\n",
            "            PReLU-65         [-1, 64, 128, 128]               1\n",
            "           Conv2d-66         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-67         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-68         [-1, 64, 128, 128]               0\n",
            "           Conv2d-69         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-70         [-1, 64, 128, 128]             128\n",
            "            PReLU-71         [-1, 64, 128, 128]               1\n",
            "           Conv2d-72         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-73         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-74         [-1, 64, 128, 128]               0\n",
            "           Conv2d-75         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-76         [-1, 64, 128, 128]             128\n",
            "            PReLU-77         [-1, 64, 128, 128]               1\n",
            "           Conv2d-78         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-79         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-80         [-1, 64, 128, 128]               0\n",
            "           Conv2d-81         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-82         [-1, 64, 128, 128]             128\n",
            "            PReLU-83         [-1, 64, 128, 128]               1\n",
            "           Conv2d-84         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-85         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-86         [-1, 64, 128, 128]               0\n",
            "           Conv2d-87         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-88         [-1, 64, 128, 128]             128\n",
            "            PReLU-89         [-1, 64, 128, 128]               1\n",
            "           Conv2d-90         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-91         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-92         [-1, 64, 128, 128]               0\n",
            "           Conv2d-93         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-94         [-1, 64, 128, 128]             128\n",
            "            PReLU-95         [-1, 64, 128, 128]               1\n",
            "           Conv2d-96         [-1, 64, 128, 128]          36,864\n",
            "      BatchNorm2d-97         [-1, 64, 128, 128]             128\n",
            "    ResidualBlock-98         [-1, 64, 128, 128]               0\n",
            "           Conv2d-99         [-1, 64, 128, 128]          36,864\n",
            "     BatchNorm2d-100         [-1, 64, 128, 128]             128\n",
            "          Conv2d-101        [-1, 256, 128, 128]         147,712\n",
            "    PixelShuffle-102         [-1, 64, 256, 256]               0\n",
            "           PReLU-103         [-1, 64, 256, 256]               1\n",
            "SubpixelConvolutionLayer-104         [-1, 64, 256, 256]               0\n",
            "          Conv2d-105        [-1, 256, 256, 256]         147,712\n",
            "    PixelShuffle-106         [-1, 64, 512, 512]               0\n",
            "           PReLU-107         [-1, 64, 512, 512]               1\n",
            "SubpixelConvolutionLayer-108         [-1, 64, 512, 512]               0\n",
            "          Conv2d-109          [-1, 3, 512, 512]          15,555\n",
            "            Tanh-110          [-1, 3, 512, 512]               0\n",
            "================================================================\n",
            "Total params: 1,547,350\n",
            "Trainable params: 1,547,350\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 1452.00\n",
            "Params size (MB): 5.90\n",
            "Estimated Total Size (MB): 1458.09\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2baI7iXj6TJB"
      },
      "source": [
        "# Calculate the one-dimensional Gaussian distribution vector\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        " \n",
        " \n",
        " # Create a Gaussian kernel, obtained by matrix multiplication of two one-dimensional Gaussian distribution vectors\n",
        " # You can set the channel parameter to expand to 3 channels\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        " \n",
        " \n",
        " # Calculate SSIM\n",
        " # Use the formula of SSIM directly, but when calculating the average value, instead of directly calculating the pixel average value, normalized Gaussian kernel convolution is used instead.\n",
        " # The formula Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y] is used when calculating variance and covariance .\n",
        " # As mentioned earlier, the above expectation operation is replaced by Gaussian kernel convolution.\n",
        "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
        "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
        "    if val_range is None:\n",
        "        if torch.max(img1) > 128:\n",
        "            max_val = 255\n",
        "        else:\n",
        "            max_val = 1\n",
        " \n",
        "        if torch.min(img1) < -0.5:\n",
        "            min_val = -1\n",
        "        else:\n",
        "            min_val = 0\n",
        "        L = max_val - min_val\n",
        "    else:\n",
        "        L = val_range\n",
        " \n",
        "    padd = 0\n",
        "    (_, channel, height, width) = img1.size()\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width)\n",
        "        window = create_window(real_size, channel=channel).to(img1.device)\n",
        " \n",
        "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
        " \n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        " \n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
        " \n",
        "    C1 = (0.01 * L) ** 2\n",
        "    C2 = (0.03 * L) ** 2\n",
        " \n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
        " \n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
        " \n",
        "    if size_average:\n",
        "        ret = ssim_map.mean()\n",
        "    else:\n",
        "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
        " \n",
        "    if full:\n",
        "        return ret, cs\n",
        "    return ret\n",
        " \n",
        " \n",
        " \n",
        "# Classes to re-use window\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.val_range = val_range\n",
        " \n",
        "        # Assume 1 channel for SSIM\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size)\n",
        " \n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        " \n",
        "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        " \n",
        "        return ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hSw3ir6cz-"
      },
      "source": [
        "def mypsnr(img1, img2):\n",
        "    max_pixel = 1.0\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    psnr = 20 * math.log(max_pixel / math.sqrt(mse), 10)\n",
        "    \n",
        "    return psnr\n",
        "    \n",
        "def myssim(img1, img2):\n",
        "    #convert to tensor\n",
        "    img1 = torch.tensor(img1).cuda()\n",
        "    img2 = torch.tensor(img2).cuda()\n",
        "\n",
        "    #convert to variable\n",
        "    img1 = Variable(img1,  requires_grad=False)\n",
        "    img2 = Variable(img2, requires_grad = True)\n",
        "    \n",
        "    # ssim_value = pytorch_ssim.ssim(img1, img2)\n",
        "    ssim_value = ssim(img1, img2)\n",
        "    \n",
        "    return ssim_value.item()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti3SUeGl671R"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbgcrB2S768U"
      },
      "source": [
        "def train_epoch(netG, netD, train_loader, content_criterion, optimiserG, optimiserD, results, epoch):\n",
        "  print(\"Training...\")\n",
        "  netG.train()\n",
        "  netD.train()\n",
        "  running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    g_update_first = True\n",
        "    batch_size = data.size(0)\n",
        "    running_results['batch_sizes'] += batch_size\n",
        "    \n",
        "    netD.zero_grad()\n",
        "    fake_img = netG(data)\n",
        "    fake_out = netD(fake_img).mean()\n",
        "    real_out = netD(target).mean()\n",
        "    d_loss = 1 - real_out + fake_out\n",
        "    d_loss.backward()\n",
        "    optimiserD.step()\n",
        "\n",
        "    if epoch > 2:\n",
        "      netG.zero_grad()\n",
        "      fake_img = netG(data)\n",
        "      fake_out = netD(fake_img).mean()\n",
        "      g_loss = content_criterion(fake_img, target) + 0.001 * (torch.mean(1 - fake_out))\n",
        "      g_loss.backward()\n",
        "      optimiserG.step()\n",
        "    else:\n",
        "      g_loss = None\n",
        "\n",
        "    # loss for current batch before optimization \n",
        "    fake_img = netG(data)\n",
        "    fake_out = netD(fake_img).mean()\n",
        "    \n",
        "    if g_loss:\n",
        "      running_results['g_loss'] += g_loss.item() * batch_size\n",
        "    running_results['d_loss'] += d_loss.item() * batch_size\n",
        "    running_results['d_score'] += real_out.item() * batch_size\n",
        "    running_results['g_score'] += fake_out.item() * batch_size\n",
        "    \n",
        "    del fake_img\n",
        "    del fake_out\n",
        "    del real_out\n",
        "    torch.cuda.empty_cache()\n",
        "    if (batch_idx+1) % 200 == 0:\n",
        "      print(\"\\tBatch: %d Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\" % (\n",
        "          batch_idx + 1,\n",
        "          running_results['d_loss'] / running_results['batch_sizes'],\n",
        "          running_results['g_loss'] / running_results['batch_sizes'],\n",
        "          running_results['d_score'] / running_results['batch_sizes'],\n",
        "          running_results['g_score'] / running_results['batch_sizes']))\n",
        "      \n",
        "  end_time = time.time()\n",
        "\n",
        "  print(\"Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f Time: %.4f\" % (\n",
        "      running_results['d_loss'] / running_results['batch_sizes'],\n",
        "      running_results['g_loss'] / running_results['batch_sizes'],\n",
        "      running_results['d_score'] / running_results['batch_sizes'],\n",
        "      running_results['g_score'] / running_results['batch_sizes'],\n",
        "      end_time - start_time))\n",
        "  \n",
        "  results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "  results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "  results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "  results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quISEASACC7j"
      },
      "source": [
        "def val_epoch(netG, netD, val_loader, results):\n",
        "    print(\"Validating...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_results = {'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "      for batch_idx, (data, target) in enumerate(val_loader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        batch_size = data.size(0)\n",
        "        val_results['batch_sizes'] += batch_size\n",
        "        fake_img = netG(data)\n",
        "        t,o = target.cpu().numpy(), fake_img.cpu().numpy()\n",
        "\n",
        "        val_results['ssim'] += myssim(t, o)\n",
        "        val_results['psnr'] += mypsnr(t, o)\n",
        "\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    print(\"PSNR: %.4f dB SSIM: %.4f Time: %.4f\" % (\n",
        "          val_results['psnr']/val_results['batch_sizes'], \n",
        "          val_results['ssim']/val_results['batch_sizes'],\n",
        "          end_time - start_time))\n",
        "    \n",
        "    results['psnr'].append(val_results['psnr']/val_results['batch_sizes'])\n",
        "    results['ssim'].append(val_results['ssim']/val_results['batch_sizes'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "adfbeaeff4104ca5911bab5745755753",
            "48354e3e8c9b41a39dc927f68753cdcd",
            "32467df61df347929a955083bbab4d68",
            "230a092b86194daa852e005953536e4f",
            "256ff7d20d344c4bbece061b0b74bf40",
            "e9c792e331da4a02a856adffd78d7726",
            "ad0a6d4338404f568efb86af40dc32fa",
            "d9c0b2b2009345218e1bbab93e4422d4",
            "8a1b390b1e654f9a8ef0952ce3be064d",
            "fad54d6fa6dc465a88974f657254545e",
            "d9f998cbfa3f4e3f86ea8695fa97accf"
          ]
        },
        "id": "jSBNP16ozNhE",
        "outputId": "a41a6b61-aca6-444e-a6b9-4dce883a8fd6"
      },
      "source": [
        "n_epochs = 200\n",
        "model_no = 6\n",
        "\n",
        "learningRate = 0.0005\n",
        "weightDecay = 1e-5\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "netG = Generator()\n",
        "netD = Discriminator()\n",
        "\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "\n",
        "# netG  # convert to half precision\n",
        "# for layer in netG.modules():\n",
        "#   if isinstance(layer, nn.BatchNorm2d):\n",
        "#     layer.float()\n",
        "\n",
        "# netD  # convert to half precision\n",
        "# for layer in netD.modules():\n",
        "#   if isinstance(layer, nn.BatchNorm2d):\n",
        "#     layer.float()\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        # m.bias.data.fill_(0.01)\n",
        "\n",
        "netG.apply(init_weights)\n",
        "netD.apply(init_weights)\n",
        "\n",
        "content_criterion = ContentLoss()\n",
        "content_criterion.to(device)\n",
        "\n",
        "optimiserG = optim.Adam(netG.parameters(), lr=learningRate, weight_decay=weightDecay)\n",
        "optimiserD = optim.Adam(netD.parameters(), lr=learningRate, weight_decay=weightDecay)\n",
        "\n",
        "schedulerG = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiserG, mode='min', factor=0.7, patience=5)\n",
        "schedulerD = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiserD, mode='min', factor=0.7, patience=5)\n",
        "\n",
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adfbeaeff4104ca5911bab5745755753",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYFtuYCc6_12"
      },
      "source": [
        "for i in range(n_epochs):\n",
        "    print(\"Epoch \", i)\n",
        "\n",
        "    if path.exists('SRGAN/model_'+ str(model_no) + '_' + str(i)) and i<4:\n",
        "      checkpoint = torch.load('SRGAN/model_' + str(model_no) + '_' + str(i))\n",
        "      netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "      netD.load_state_dict(checkpoint['netD_state_dict'])\n",
        "      optimiserG.load_state_dict(checkpoint['optimiserG_state_dict'])\n",
        "      optimiserD.load_state_dict(checkpoint['optimiserD_state_dict'])\n",
        "      results = checkpoint['results']\n",
        "      continue\n",
        "\n",
        "    print(\"LRs: \", optimiserG.param_groups[0]['lr'], optimiserD.param_groups[0]['lr'])\n",
        "    \n",
        "    train_epoch(netG, netD, train_loader, content_criterion, optimiserG, optimiserD, results, i)\n",
        "    val_epoch(netG, netD, val_loader, results)\n",
        "    \n",
        "    torch.save({\n",
        "            'epoch': i,\n",
        "            'netG_state_dict': netG.state_dict(),\n",
        "            'netD_state_dict': netD.state_dict(),\n",
        "            'optimiserG_state_dict': optimiserG.state_dict(),\n",
        "            'optimiserD_state_dict': optimiserD.state_dict(),\n",
        "            'results': results,\n",
        "            }, 'SRGAN/model_' + str(model_no) + '_' + str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1vgCM9T7kcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920ef442-3a2f-4a95-958d-c399f57eeb8f"
      },
      "source": [
        "checkpoint = torch.load('SRGAN/model_6_34')\n",
        "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "\n",
        "results = checkpoint['results']      \n",
        "PSNR = results['psnr']\n",
        "SSIM = results['ssim']\n",
        "\n",
        "print(PSNR)  \n",
        "print(SSIM)\n",
        "print(np.argmax(PSNR), np.max(PSNR))\n",
        "print(np.argmax(SSIM), np.max(SSIM))\n",
        "print(len(val_dataset))\n",
        "for i in range(35):\n",
        "  if PSNR[i]/100>26:\n",
        "    print(i, PSNR[i]/100, SSIM[i]/100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1030.5273474642831, 1027.5995542532137, 1058.5124003434846, 2203.493038737403, 2359.4276393697887, 2504.3242278720636, 2487.444830609717, 2444.485887764993, 2395.966601029158, 2512.1139754503124, 2246.1774055340534, 2597.0810326571723, 2533.2055271415425, 2437.3428699436313, 2588.3552079343053, 2672.441981853846, 2622.5102374884646, 2633.2591295534494, 2648.649254338814, 2656.977963741113, 2461.2712855144937, 2675.6570692382215, 2678.6784230218923, 2559.7094076021776, 2648.9757784152434, 2628.448673179513, 2632.8632968451448, 2585.3721527001817, 2701.7161700379247, 2709.160020957549, 2708.0177240609796, 2691.7816380470776, 2518.239474090298, 2690.083472183182, 2617.4244692101406]\n",
            "[4.728824796155095, 4.4555251728743315, 5.332370828371495, 62.24700404703617, 67.59241497516632, 69.19052425026894, 69.70718145370483, 69.51358643174171, 71.3279781639576, 72.8458186686039, 67.78799712657928, 73.2539653480053, 73.35457733273506, 72.11695542931557, 72.12467968463898, 75.25061735510826, 72.3614450097084, 73.61291518807411, 72.96423470973969, 72.87960439920425, 70.06411039829254, 74.73016628623009, 75.28745895624161, 73.76934584975243, 74.31809347867966, 73.528101593256, 76.03824889659882, 72.6861321926117, 75.32094150781631, 74.8539534509182, 75.29732820391655, 74.69545677304268, 73.52210760116577, 75.65623772144318, 74.37517195940018]\n",
            "29 2709.160020957549\n",
            "26 76.03824889659882\n",
            "100\n",
            "15 26.724419818538458 0.7525061735510826\n",
            "16 26.225102374884646 0.723614450097084\n",
            "17 26.332591295534495 0.7361291518807411\n",
            "18 26.486492543388138 0.7296423470973968\n",
            "19 26.56977963741113 0.7287960439920426\n",
            "21 26.756570692382216 0.7473016628623008\n",
            "22 26.786784230218924 0.752874589562416\n",
            "24 26.489757784152435 0.7431809347867966\n",
            "25 26.28448673179513 0.73528101593256\n",
            "26 26.328632968451448 0.7603824889659881\n",
            "28 27.017161700379248 0.7532094150781632\n",
            "29 27.09160020957549 0.748539534509182\n",
            "30 27.080177240609796 0.7529732820391655\n",
            "31 26.917816380470775 0.7469545677304268\n",
            "33 26.90083472183182 0.7565623772144318\n",
            "34 26.174244692101407 0.7437517195940018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc0MzsirS0QU"
      },
      "source": [
        "def test_epoch(netG, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = netG(data)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_SRGAN_6_29_Structures/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_28wRHiF0GdG"
      },
      "source": [
        "def test_epoch(netG, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        size = (data.size(2)*4, data.size(3)*4)\n",
        "        data_size = (200, int(data.size(3)/data.size(2)*200))\n",
        "        if data.size(3) > data.size(2):\n",
        "          data_size = (int(data.size(2)/data.size(3)*200), 200)\n",
        "        print(data.size())\n",
        "        data = F.interpolate(data, data_size)\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = netG(data)\n",
        "        fake_img = F.interpolate(fake_img, size)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_SRGAN_6_29_Scaled200_4_Valid/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUugQ2x5bC1"
      },
      "source": [
        "def test_epoch(netG, test_loader):\n",
        "    print(\"Testing...\")\n",
        "    netG.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        size = (data.size(2)*4, data.size(3)*4)\n",
        "        data_size = (200, int(data.size(3)/data.size(2)*200))\n",
        "        if data.size(3) > data.size(2):\n",
        "          data_size = (int(data.size(2)/data.size(3)*200), 200)\n",
        "        print(data_size)\n",
        "        data = F.interpolate(data, data_size, mode='bilinear', align_corners=True)\n",
        "        batch_size = data.size(0)\n",
        "        fake_img = netG(data)\n",
        "        fake_img = F.interpolate(fake_img, size, mode='bilinear', align_corners=True)\n",
        "        # np.save(\"Test_5_111/\" + label[0][:-4], fake_img[0].cpu().numpy().transpose(1,2,0))\n",
        "        save_image(fake_img[0].cpu(), \"Test_SRGAN_6_29_Scaled200_5/\" + label[0])\n",
        "        del fake_img\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1o33BgB6PV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be23413-f5d2-409b-f00c-dcd681ff97c6"
      },
      "source": [
        "checkpoint = torch.load('SRGAN/model_6_29')\n",
        "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
        "!mkdir Test_SRGAN_6_29_Structures\n",
        "test_epoch(netG, test_loader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}